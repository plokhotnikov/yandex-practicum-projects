{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация комментариев пользователей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Постановка задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание \n",
    "\n",
    "На основе исходных данных с разметкой о токсичности правок разработать модель, которая бы классифицировала комментарии пользователей о товарах интернет-магазина на позитивные и негативные. Модель должна соответствовать значению метрики качества F1 не меньше 0.75. \n",
    "\n",
    "### Описание данных\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hyperopt in c:\\users\\1\\anaconda3\\lib\\site-packages (0.2.7)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\1\\anaconda3\\lib\\site-packages (from hyperopt) (2.6.3)\n",
      "Requirement already satisfied: py4j in c:\\users\\1\\anaconda3\\lib\\site-packages (from hyperopt) (0.10.9.5)\n",
      "Requirement already satisfied: six in c:\\users\\1\\anaconda3\\lib\\site-packages (from hyperopt) (1.16.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\1\\anaconda3\\lib\\site-packages (from hyperopt) (2.0.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\1\\anaconda3\\lib\\site-packages (from hyperopt) (1.7.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\1\\anaconda3\\lib\\site-packages (from hyperopt) (4.62.3)\n",
      "Requirement already satisfied: future in c:\\users\\1\\anaconda3\\lib\\site-packages (from hyperopt) (0.18.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\1\\anaconda3\\lib\\site-packages (from hyperopt) (1.21.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\1\\anaconda3\\lib\\site-packages (from tqdm->hyperopt) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "#!pip install torch-lr-finder\n",
    "#!pip install transformers\n",
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm, notebook\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "pd.options.mode.chained_assignment = None\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "from hyperopt import hp, tpe, Trials, STATUS_OK\n",
    "from hyperopt.fmin import fmin\n",
    "from functools import partial\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82442</th>\n",
       "      <td>What a hypocrite this creep Chavez is!\\n\\nFrom the main article about Hugo Chavez:\\n\\nChávez was raised a Roman Catholic, although he has had a series of disputes with both the Venezuelan Catholic hierarchy and Protestant groups like the New Tribes Mission. He has traditionally kept his own faith a private matter, but over the course of his presidency, Chávez has become increasingly open to discussing his religious views, stating that both his faith and his interpretation of Jesus' personal life and ideology have had a profound impact on his left-wing and progressivist views. He often invokes God and asks for prayer in speeches, as he did when he asked Venezuelans to pray for Fidel Castro's health.\\n\\nI find it ironic that an atheist such as Hugo Chavez would ask the Venezuelan people to pray to God for another atheist's (Fidel Castro) health! This just shows what a hypocrite and liar Chavez is!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132112</th>\n",
       "      <td>\"\\nAh I needed to stay away for a day and clear my mind. I wasn't gone for long. )  | talk \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30078</th>\n",
       "      <td>The true words of a moron</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130901</th>\n",
       "      <td>, 7 September 2010 (UTC)\\n\\nThat Op-ed is 90% about criticism of the US system and I'm not sure that is relevant to this article.  Did you see where he says there's a pretty good argument that she should have been found innocent?  Fair enough. Wikipedia articles are supposed to report facts about opinions. Is his opinion notable? That's a close call. I'm calling for quite a bit of discussion about what observers say about the trial.  He's saying he doesn't like the US response, not that he agrees with the verdict.  The lengthy criticism section I put together wasn't necessarily intended to go in as is.  The idea is that it puts in one place content that I believe belongs in various places in the article.  Feel free to say what you think is wrong with what I wrote in that criticism section.  13:25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90549</th>\n",
       "      <td>I didn't ask how often you jerk off.  A Simpsons episode is where the mass of twitchy muscle is from.  69.158.165.129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130019</th>\n",
       "      <td>\"\\n File:CarlsburgBeer.JPG listed for deletion \\nA file that you uploaded or altered, File:CarlsburgBeer.JPG, has been listed at Wikipedia:Files for deletion. Please see the discussion to see why it has been listed (you may have to search for the title of the image to find its entry). Feel free to add your opinion on the matter below the nomination. Thank you.   hi! \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77359</th>\n",
       "      <td>\"\\n\\nPS: “Blackpearl14\"\" Do you, your friends and family or any contributors, editors, administrators or Mr. Wales or their friends and family own stock within the Walt Disney Company?  The Walt Disney Company page is not neutral, it is a series of promotional pages including links to products and causes of the Walt Disney Company.   Many of the other statements on the Walt Disney Company page don’t follow your so-called neutral definition.  Following your own claim of “neutral”, the entire page would have to be deleted per your own standards.  Furthermore, the lawsuit sentence that was placed on it, was exactly as the other statements of “criticism” within the Walt Disney Company page, yet you claim it’s not neutral.   Clearly you enforce double standards and don’t adhere to wikipedia’s own written polices.  \\nCriticism\\nDisney has on several occasions prompted action from religious groups such as the Catholic League, due to purported insensitive broadcasting, and the release of films, which the league and others found offensive. Disney has faced boycotts from Baptist groups, \"\"Assemblies of God\"\", and Catholic groups in the past. (boycott 1;boycott 2;boycott 3)  \\nThe worldwide commercial success of the Disney brand is viewed by some as detrimental to cultural diversity (see Disneyfication).\\nDisney is one among several American companies lobbying for more stringent enforcement of intellectual property around the world and continued copyright term extensions, posing a perceived threat to the existence of the public domain; see Copyright Term Extension Act.\\nDisney has been accused of human rights violations regarding the working conditions in factories that produce their merchandise.http://www.somo.nl/monitoring/reports/hkcic01-02.htmhttp://www.cbc.ca/news/story/2001/06/18/sweatshops_010618.html source\\nDisney has been criticized by animal welfare groups for its import, use and frequent deaths of wild animals at its Animal Kingdom theme parkCaution: Live Animals - TIME as well as for using purebred dogs in movies such as 101 Dalmatians, which these groups claim leads to creating an artificial demand for these purebred dogs many of whom are later abandoned or surrendered to shelters or rescue groups.CNN.com - 'Nemo' fans net fish warning - Jun. 30, 2003\\nDisney has been criticized in the Abaco Islands for their role in a dredging operation on Great Guana Cay that is said to be responsible for a wide array of environmental problems, including widespread death of coral communities. \\nDisney films are also notable for their ongoing lack of cultural understanding when portraying non-white ethnic groups on screen. They have been criticised for their liberal use of stereotyping, in both appearance and dialogue. The 9 Most Racist Disney Characters\\n Independent film maker Royce Mathew sued  www.disneylawsuit.com the Walt Disney Company, Jerry Bruckheimer Inc./films, Ted Elliott and Terry Rossio in Federal Court claiming they plagiarized his supernatural pirate move for the Pirates of the Caribbean movie.\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  text  \\\n",
       "82442   What a hypocrite this creep Chavez is!\\n\\nFrom the main article about Hugo Chavez:\\n\\nChávez was raised a Roman Catholic, although he has had a series of disputes with both the Venezuelan Catholic hierarchy and Protestant groups like the New Tribes Mission. He has traditionally kept his own faith a private matter, but over the course of his presidency, Chávez has become increasingly open to discussing his religious views, stating that both his faith and his interpretation of Jesus' personal life and ideology have had a profound impact on his left-wing and progressivist views. He often invokes God and asks for prayer in speeches, as he did when he asked Venezuelans to pray for Fidel Castro's health.\\n\\nI find it ironic that an atheist such as Hugo Chavez would ask the Venezuelan people to pray to God for another atheist's (Fidel Castro) health! This just shows what a hypocrite and liar Chavez is!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "132112  \"\\nAh I needed to stay away for a day and clear my mind. I wasn't gone for long. )  | talk \"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "30078   The true words of a moron                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "130901  , 7 September 2010 (UTC)\\n\\nThat Op-ed is 90% about criticism of the US system and I'm not sure that is relevant to this article.  Did you see where he says there's a pretty good argument that she should have been found innocent?  Fair enough. Wikipedia articles are supposed to report facts about opinions. Is his opinion notable? That's a close call. I'm calling for quite a bit of discussion about what observers say about the trial.  He's saying he doesn't like the US response, not that he agrees with the verdict.  The lengthy criticism section I put together wasn't necessarily intended to go in as is.  The idea is that it puts in one place content that I believe belongs in various places in the article.  Feel free to say what you think is wrong with what I wrote in that criticism section.  13:25                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "90549   I didn't ask how often you jerk off.  A Simpsons episode is where the mass of twitchy muscle is from.  69.158.165.129                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "130019  \"\\n File:CarlsburgBeer.JPG listed for deletion \\nA file that you uploaded or altered, File:CarlsburgBeer.JPG, has been listed at Wikipedia:Files for deletion. Please see the discussion to see why it has been listed (you may have to search for the title of the image to find its entry). Feel free to add your opinion on the matter below the nomination. Thank you.   hi! \"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "77359   \"\\n\\nPS: “Blackpearl14\"\" Do you, your friends and family or any contributors, editors, administrators or Mr. Wales or their friends and family own stock within the Walt Disney Company?  The Walt Disney Company page is not neutral, it is a series of promotional pages including links to products and causes of the Walt Disney Company.   Many of the other statements on the Walt Disney Company page don’t follow your so-called neutral definition.  Following your own claim of “neutral”, the entire page would have to be deleted per your own standards.  Furthermore, the lawsuit sentence that was placed on it, was exactly as the other statements of “criticism” within the Walt Disney Company page, yet you claim it’s not neutral.   Clearly you enforce double standards and don’t adhere to wikipedia’s own written polices.  \\nCriticism\\nDisney has on several occasions prompted action from religious groups such as the Catholic League, due to purported insensitive broadcasting, and the release of films, which the league and others found offensive. Disney has faced boycotts from Baptist groups, \"\"Assemblies of God\"\", and Catholic groups in the past. (boycott 1;boycott 2;boycott 3)  \\nThe worldwide commercial success of the Disney brand is viewed by some as detrimental to cultural diversity (see Disneyfication).\\nDisney is one among several American companies lobbying for more stringent enforcement of intellectual property around the world and continued copyright term extensions, posing a perceived threat to the existence of the public domain; see Copyright Term Extension Act.\\nDisney has been accused of human rights violations regarding the working conditions in factories that produce their merchandise.http://www.somo.nl/monitoring/reports/hkcic01-02.htmhttp://www.cbc.ca/news/story/2001/06/18/sweatshops_010618.html source\\nDisney has been criticized by animal welfare groups for its import, use and frequent deaths of wild animals at its Animal Kingdom theme parkCaution: Live Animals - TIME as well as for using purebred dogs in movies such as 101 Dalmatians, which these groups claim leads to creating an artificial demand for these purebred dogs many of whom are later abandoned or surrendered to shelters or rescue groups.CNN.com - 'Nemo' fans net fish warning - Jun. 30, 2003\\nDisney has been criticized in the Abaco Islands for their role in a dredging operation on Great Guana Cay that is said to be responsible for a wide array of environmental problems, including widespread death of coral communities. \\nDisney films are also notable for their ongoing lack of cultural understanding when portraying non-white ethnic groups on screen. They have been criticised for their liberal use of stereotyping, in both appearance and dialogue. The 9 Most Racist Disney Characters\\n Independent film maker Royce Mathew sued  www.disneylawsuit.com the Walt Disney Company, Jerry Bruckheimer Inc./films, Ted Elliott and Terry Rossio in Federal Court claiming they plagiarized his supernatural pirate move for the Pirates of the Caribbean movie.\"   \n",
       "\n",
       "        toxic  \n",
       "82442   1      \n",
       "132112  0      \n",
       "30078   1      \n",
       "130901  0      \n",
       "90549   1      \n",
       "130019  0      \n",
       "77359   0      "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1    16225 \n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратим внимание на дисбаланс классов в исходной выборке: значений \"1\" в столбце целевого признака составяет чуть больше 10% от общего количества записей. Это необходимо будет учесть при построении моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Прописные буквы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть предположение, что токсичные комментарии связаны с повышенным эмоциональным состоянием человека, которые он выражает через набор текста прописными буквами для усиления эффекта воздействия. Думается, что человек в спокойном состоянии для нейтрального комментария будет придерживаться правил правписания. Проверим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27548     FUCK YOU \\n\\nFUCK YOU ASSHOLE                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "42557     Jesus Christ, I can't edit anything without stupid pimple faced kids editing my work.                                                                                                                                                                                                                                                                                                                                                             \n",
       "141377    \"\\n Well, when the root problem is a miserable, lowlife scumbag like you? BUNG-HO(LE)?! Eh, I basically just tell you to go fuck yourself. Did you really think a \"\"win\"\" would be that easy, dumbass? Really? Oh no, no, no... I tried it the nice way... But now you're about to learn just what you fucked with. Enjoy! Couldn't happen to a more deserving pile of shit. Hugs, kisses - and get used to my foot in your ass... 69.50.214.99  \"\n",
       "131805    I HAVE NO LIFE, AND IF I DON'T GET TO EVER HAVE SEX THEN I WILL MAKE EVERYONE'S LIFE I CAN AS MISERABLE AS POSSIBLE!                                                                                                                                                                                                                                                                                                                              \n",
       "62480     ON A SIDE NOTE \\n\\nStop being a little cry-baby and grow up. Stop complaining to your administrators behind their computers. I'm sure you're a grown man. Grow up and act like one.                                                                                                                                                                                                                                                               \n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['toxic'] == 1]['text'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоит отметить, что нас интересуют не просто прописные буквы в тексте, а идующие подряд, а также их соотношение по отношению к общему слов в тексте. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['length'] = data['text'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интересно также посмотреть, как отличаются по размеру текстов токсичные и нейтральные комментарии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuQAAAGDCAYAAABjvQUaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA7XElEQVR4nO3de7gkVXnv8e8vAwgiigScw/2iYASjBBFIjGa8g7fxJF5ADYgagoFoThIjqPEaoolRI94QFQUVESXoGEnwutFEERhFFBQdEMMICIICg4gOvOePWjs0zZ69a5jd08P09/M8/UxX1Vqr3qrVu+ft1auqU1VIkiRJGo/fGncAkiRJ0iQzIZckSZLGyIRckiRJGiMTckmSJGmMTMglSZKkMTIhlyRJksbIhFySJEkaIxNyTZwklyW5OcmKJD9N8sEk9xp3XJIkaTKZkGtSPbWq7gXsBTwceNWY45EkSRPKhFwTrap+AvwH8GCAJIcm+V6SG5NcmuTPB8snWZzk/CQ3JLkkyf5t/VSSX7VR9xVtBP6ygXqXJTk6yUVJft5G5Tce2P6U1u4vknwtyUOG9vuRJL8eaHv5wLZ7JPmXJP/TRvyPS7LJwPadktRAbLcmeVHb9ltJjmrHcm2SU5NsMVRvg6E4XtueLxqK41mt/IsG1r2gnc+fJzkzyY4z9cPwvpL8RZILk/x2W94myZIk1yVZluTPhuo/vx3X9DFWkgcM9M3g8X5nOu4Z9ju8fJ8kH0hyZZKfJPmHJAsG9vtnA6+Xi5LsleSdQ3Hc1J7/xwyvlauTHDPQ3pOTfKu9vi6fPterOGe/aG38aujYn9u279deS79I8u0kiwbqDp6T+7d9PXUNj2uVfZTktUl+08r/IsnpSTZbxXGtTtmXJrmqxXlBkj8a2Pb2dlw3JFma5JF99tFeS/81UPbv2vE+ri0vSPKKdH8zN7a2t2/bBl93O6T7W/1IW55+bX16oO37tv4b3N8fJDk3yfXt3z8YiGP6/N+W27/lu7Bt/1CSfxho54wM/f0OnbsHtdfBL9L9rT2trX927vhe8b/va6toZ5X7TbJFkuXTr60k92qvjYNX0dZUkjcmOacd/6fT3o/a9k+0/r4+yVeS7DGw7Z+T/Kz1ydlJpt/T+57330ny+fb6vTjJs4aO8bi2/cYkZ2XgvWxVfTZwTDP+vUt3UFU+fEzUA7gMeFx7vj1wIfCGtvxk4P5AgD8Cfgns1bbtA1wPPJ7uw+y2wO+0bVPAiwb28TjgsqF9frftbwvgv4F/aNv2Aq4G9gUWAIe08vcYqP9R4DXt+SJg+cC2fwWWtHY3Az4DvHFg+y5AAQuGYwX+Cjgb2A64B/Be4GNt206t3gYDbX0EeO1wHMCGwMXAFQNtPx1YBjwI2IDuW4ivraJP/ndfwIHApcB2A9vPAt4NbAzsCVwDPHZg+wuArw4sF/CAGY73UGD5QNw7tLIbzXTMwKfaOdkUuB9wDvDnbdszgZ/QfcMS4AHAjkPH9b9xDKwbjGc34FfAgwfO6e/Svb4eAvwUePocr+fnA/81tG5b4FrgSa2tx7flrQZjAP5P66ODB+re1eNaZR8BrwU+0p7fGzgfOHIVx7M6ZXcB7tPiPBxYOrDtecBv072m/ga4Cth4rn0Mnk/gvu318nNuf894GfAd4IFtvw8FfnuG192Jre70fnZq278DbN3WvQS4aGB/W7R9/WmL+6C2/Nureg8bWPchbn9PWdT2fYe/34GyG7Z+fwWwEfAY4Ebggat6rc7y+pt1v8AT2rm/H/A+4JOztDVF99p7MN3f3GnT52/g73wzuveqfwXOH9j2QOCedO+h/wicthrnfVPgcrr3hw3o3pN/BuwxcIw3Ao9q+3573z5jlr93Hz4GH46Qa1J9KskvgP+iSyT+EaCqPltVl1TnLOBzwPTI2guBE6rq81V1W1X9pKq+vxr7fGdVXV5V1wHH0L1xA/wZ8N6q+kZV3VpVJwK3APsN1N0E+PVwg0nS6v+/qrquqm5sx3LgQLGNgNuq6tYZYvpz4JVVtbyqbqFLVJ6xqlG1Wfw58A3gB0Pr3lhV36uqlS2uPbOKUfJmf+ADwAFVNT2KvT3wh8DLq+pXVXU+8H66/wAHj/FO52dQum8k/h54w8Dqn7Z6T5ih/ELgAOCvquqmqroaeBu3n9sXAf9cVee218uyqvrxbDHMYAPgVroPelTVVFV9p72+LgA+RvfBcHU9Dzijqs5obX0eOI8uQZ+2Od3r+6NVddLA+tU+rp59NG0B3YeEa3scx6xlq+rSqrp+OgzgmwPbPlJV11bVyqp6C10i9cDV3McrgRNo/dO8CHhVVV3czs+3q+oOddN9w/X7dEn5sBPpkn6Ag4fKPBn4YVV9uMX9MeD7wFPpqb0n/DPw6lmK7QfcC3hTVf26qr4E/Du3vyettlXtt6o+B3wC+CLd8f35nWvfwYer6rtVdRPd3+uz0r6VqqoTqurGgfeqhya5T9t2cVX9ku51AAOvhWa28/4UugGUD7bz/k26DwPPGCjz2ar6Stv3K4Hfb6/71emzO/y9S4NMyDWpnl5Vm1fVjlX1F1V1M0CSA9rXnde1hP1JwJatzvbAJWuwz8sHnv8Y2KY93xH4m/bV8S/afrcf2A7dSOY1M7S5Fd2o0NKBuv/Z1k+bHsGZyY7A6QN1v0f3H8bCgTI/G9j+rOEG0n3V/3d0/3kOt/32gbrX0f1nue0qYoEuibuMOyah2wDTHzam/XiondmOcdpLgTPpRvIBaP+5HgG8t8V4wVD8GwJXDhzDe+lG+mDNXg/HtvYupPuQdzlAkn2TfDnJNUmupxv13XKWdlZlR+CZQ6+pPwS2HijzemAF8Ngkg/8X3JXj6tNHz2pxXAPcRPdNzqr0LpvkKLpvst5Al1ROr/+bdNNurm9t3Yc7nstZ95FkB7rX+5uHdtnn/PwT3d/Db2bY9mHguUn2pXtP+OnAtm3oztug4fM4l2fRfbj40ixltgEur6rb1mA/q7Pf4+lGvT84/OFlBsPvkxsCW6abKvSmdFOFbqB7n4CBPk3ybrq+fA7w5aF2ZzvvOwL7Dv29PJfuffdOcVXVCrr3s23o12cz/r1Lg0zIpSbJPehGRf4FWFhVmwNncPuIy+V001nuqu0Hnu9AN71jut1j2geE6cc920gLSTak+8/s2zO0+TPgZrqvVqfr3qe6C1an7cYdR64HXU43Gj24742rm1s/bcvpbcCpM7TxMuDUGUZRL6eb3jHY9iZV9bVVxALdCN2zgWPa6BN052mL3HEe8Q50X233OUboEvYjgdcNb6iq91fVtu34BufuX073TcWWA/Hfu6r2GNh+V18PL2n72wL4wyTTI5Mn000/2r6q7gMcx+2vv9VxOd1I4+C537Sq3jRQ5lS6JB26czNYd3WPq08fndqO+Z500wfeMkt7vcu2Y7on3ejnqUk2Tzdf/OV0SeJ9W1vXc8dzOdc+/oHum4Ibh9bPdX4eQ5ckzvS3Al3S+l26D3fvH9p2BV1yOGj4PM5mQ7oPJi+fo9wVwPZDH8RWZz+999tGt98LnAS8OG2O/SyG3yd/Q/c+9xxgMd10wPvQTUWBgT6tqr+g6883A6cPtTvbeb8cOGvo7+VeVfXimeJKd1euLejOY58+W9Xfu/S/TMil221E97X2NcDKJAdwx6kMHwAOTfLYdBcHbpvkd1aj/SOSbJfuIqVXAB9v698HHN5GR5Nk03QX900nN4fSzcE8b7jBNsL1PuBtSe4H0OJ6Ynu+Pd3I8KdWEdNxdMnvjq38VkkWr8Yxbdbim+lCpeOAo9MuvEp3geQz52jvq1X1XeBYuv84aaNJXwPemGTjNh3ghXTz6knyCLr56p+escXOXwEfqKqreh4XVXUl3ZSOtyS5d+vz++f2CwffD/xtkoe1fnvAHNNxZnIr3fzW6W80NqMbaf5Vkn3okpC74iPAU5M8sY0sbpzuItztBsr8V3v9vAB4dZJd7upxzdVHQ24bOubZzFo2ye65fXrVJq38r+jO40q6v+UNkryabq543308gO6ajvfOUP79wBuS7NrOz0PSLj5uXgu8rKpqluN6G9289f8cWn8GsFuS56S7KPLZwO4MjPzP4U/prtO4YI5y36AbSf67JBumu+D3qcApPfezOvt9Rfv3BXSDHSdl4MLoGTyv9es96b7F+WR10+02o/uAfC1d0v2Pg5WSPLh9wAjd+/jNM7S9qvP+73Tn/U/b+dgwycOTPGigzJOS/GGSjeg+fHyjve5Xp8+G/96l/2VCLjVtJOwldCNbP6dLhpYMbD+HLvl8G91o21nceWRkNifTJXiXtsc/tHbPo5sH/s6232W0uY7p7pjxXmBn4MZ0dzr4D2CbJMe1dl/e6pzdvsr9ArfPlT2T7qKit60ipre3Y/xckhvpLvDcdzWO6d7AsVV1p+kiVXU63Vf3p7S4vks3J7uPNwJbJzmkLR9ENyJ2Bd3I12uq6vNJdqebC/q3VfWNWdpbQJcMrK6D6T6oXUTXN5+kTfuoqk/QfRA5me6Cr0/RjYD18c7Wl5fRzTf9QFv/F8DrW1+8mlWPss6qJQqL6ZKha+hGAF/GDO/5VfUD4E3A+5NkDY5rxj4a2P7sdszX0iUsr7hTC6tf9i/pLoi+nm5e77Oq6ld0r/v/oPvW5Md0SfrwNIHZ9rGQbp74TFNO3krXL58DbqDru00Gtn+rqqZmOTaqu17k+TV0XUebzvEUuotQr6WbCvaUqvrZbO0NuC93njo20/5/DTyN7u/xZ3QX4x5cq3dNzJz7TfIw4K9b27fSvR8UcNQsbX2Y7iLKq+guEH5JW38SXV/+hO7v8eyhem+k+xu9lm7u951GoWc57zfSDb4cSPf6varFeo+BYicDr6GbqvIwuiktfftsVX/v0v/K7B/iJc2HdLdAfFFVfWE16z0f2KmqXju0fju6Oxs8f55ClKSxSjJFd1eV4SklY5XkQ3R3ZvL3KjQyjpBL67ab6Ebhhq2kG6mRJEl3c6t7azNJa1GbPjDT+qvovgqWJEl3c05ZkSRJksbIKSuSJEnSGJmQS5IkSWM00XPIt9xyy9ppp53W+n5vuukmNt1007W+X61d9vNksJ8ng/08Gezn9d84+3jp0qU/q6oZ70M/0Qn5TjvtxHnn3em3VkZuamqKRYsWrfX9au2ynyeD/TwZ7OfJYD+v/8bZx0mGf9H6fzllRZIkSRojE3JJkiRpjEzIJUmSpDEyIZckSZLGyIRckiRJGiMTckmSJGmMTMglSZKkMTIhlyRJksbIhFySJEkaIxNySZIkaYxMyCVJkqQxMiGXJEmSxsiEXJIkSRqjDcYdwKTa55gvzGt757zycfPaniRJktYOR8glSZKkMTIhlyRJksbIhFySJEkaIxNySZIkaYxMyCVJkqQxMiGXJEmSxsiEXJIkSRojE3JJkiRpjEaakCfZP8nFSZYlOWqG7UlybNt+QZK95qqb5A2t7PlJPpdkm7Z+pyQ3t/XnJzlulMcmSZIkzYeRJeRJFgDvAg4AdgcOSrL7ULEDgF3b4zDgPT3qvrmqHlJVewL/Drx6oL1LqmrP9jh8NEcmSZIkzZ9RjpDvAyyrqkur6tfAKcDioTKLgZOqczaweZKtZ6tbVTcM1N8UqBEegyRJkjRSG4yw7W2ByweWlwP79iiz7Vx1kxwDHAxcDzx6oNzOSb4F3AC8qqq+OhxUksPoRuNZuHAhU1NTq3VQ82HFihW84P7z+zliHMeh2a1YscJ+mQD282SwnyeD/bz+W1f7eJQJeWZYN5yFrqrMrHWr6pXAK5McDRwJvAa4Etihqq5N8jDgU0n2GBpRp6qOB44H2HvvvWvRokU9D2f+TE1NccK3V85rm+ccuGhe29Oam5qaYhyvL61d9vNksJ8ng/28/ltX+3iUU1aWA9sPLG8HXNGzTJ+6ACcDfwJQVbdU1bXt+VLgEmC3NYhfkiRJGrlRJuTnArsm2TnJRsCBwJKhMkuAg9vdVvYDrq+qK2erm2TXgfpPA77f1m/VLgYlyS50F4peOrrDkyRJktbcyKasVNXKJEcCZwILgBOq6sIkh7ftxwFnAE8ClgG/BA6drW5r+k1JHgjcBvwYmL6byqOA1ydZCdwKHF5V143q+CRJkqT5MMo55FTVGXRJ9+C64waeF3BE37pt/Z+sovxpwGlrEq8kSZK0tvlLnZIkSdIYmZBLkiRJY2RCLkmSJI2RCbkkSZI0RibkkiRJ0hiZkEuSJEljZEIuSZIkjZEJuSRJkjRGJuSSJEnSGJmQS5IkSWNkQi5JkiSNkQm5JEmSNEYm5JIkSdIYmZBLkiRJY2RCLkmSJI2RCbkkSZI0RibkkiRJ0hiZkEuSJEljZEIuSZIkjZEJuSRJkjRGJuSSJEnSGJmQS5IkSWNkQi5JkiSNkQm5JEmSNEYm5JIkSdIYmZBLkiRJY2RCLkmSJI2RCbkkSZI0RibkkiRJ0hiZkEuSJEljZEIuSZIkjVGvhDzJjkke155vkmSz0YYlSZIkTYY5E/IkfwZ8EnhvW7Ud8KkRxiRJkiRNjD4j5EcAjwBuAKiqHwL369N4kv2TXJxkWZKjZtieJMe27Rck2Wuuukne0Mqen+RzSbYZ2HZ0K39xkif2iVGSJEkapz4J+S1V9evphSQbADVXpSQLgHcBBwC7Awcl2X2o2AHAru1xGPCeHnXfXFUPqao9gX8HXt3q7A4cCOwB7A+8u7UjSZIkrbP6JORnJXkFsEmSxwOfAD7To94+wLKqurQl9KcAi4fKLAZOqs7ZwOZJtp6tblXdMFB/U27/cLAYOKWqbqmqHwHLWjuSJEnSOqtPQn4UcA3wHeDPgTOAV/Woty1w+cDy8rauT5lZ6yY5JsnlwHNpI+Q99ydJkiStUzaYq0BV3ZbkRODrbdXFVTXnlBUgMzXXs8ysdavqlcArkxwNHAm8puf+SHIY3fQYFi5cyNTU1Eyxj9SKFSt4wf37nML+xnEcmt2KFSvslwlgP08G+3ky2M/rv3W1j+dMyJMsAk4ELqNLerdPckhVfWWOqsuB7QeWtwOu6Flmox51AU4GPkuXkPfZH1V1PHA8wN57712LFi2a4zDm39TUFCd8e+W8tnnOgYvmtT2tuampKcbx+tLaZT9PBvt5MtjP6791tY/7TFl5C/CEqvqjqnoU8ETgbT3qnQvsmmTnJBvRXXC5ZKjMEuDgdreV/YDrq+rK2eom2XWg/tOA7w+0dWCSeyTZme5C0XN6xClJkiSNzZwj5MCGVXXx9EJV/SDJhnNVqqqVSY4EzgQWACdU1YVJDm/bj6Obj/4kugswfwkcOlvd1vSbkjwQuA34MTDd3oVJTgUuAlYCR1TVrT2OT5IkSRqbPgn5eUk+AHy4LT8XWNqn8ao6gy7pHlx33MDzorvPea+6bf2fzLK/Y4Bj+sQmSZIkrQv6JOQvpkuaX0I3h/wrwLtHGZQkSZI0KfrcZeUW4K3tIUmSJGke9bnLyo+Y4faBVbXLSCKSJEmSJkifKSt7001V+RLw6NGGI0mSJE2WPlNWrgVIsnL6uSRJkqT50WfKyhbt6YIk96X9ImZVXTfKwCRJkqRJ0GfKylJu/zn7b7Z1BTiHXJIkSVpDfaas7Lw2ApEkSZImUZ8pKwfPtL6qTpr/cCRJkqTJ0mfKysPbv88CTm3PCzAhlyRJktZQnykrfwmQ5A+nn0uSJEmaH7+1GmXv9ONAkiRJktZMnznk76BLxrdLcuz0+qp6ySgDkyRJkiZBnznk57V/l44yEEmSJGkS9ZlDfuLaCESSJEmaRH2mrOwKvBHYHdh4en1V+cNAkiRJ0hrqc1HnB4H3ACuBR9Pd7vDDowxKkiRJmhR9EvJNquqLQKrqx1X1WuAxow1LkiRJmgx9Lur8VZLfAn6Y5EjgJ8D9RhuWJEmSNBn6jJD/FXBP4CXAw4A/BQ4ZYUySJEnSxOhzl5Vz29MVwKGjDUeSJEmaLHOOkCd5dpJPJnlsku8nuTrJ89ZGcJIkSdL6rs+UlTcApwCnAU8BHgIcPcqgJEmSpEnRJyG/qao+Cfy4qpZV1VXALSOOS5IkSZoIfe6ysm2SY4Gt278Bth1tWJIkSdJk6JOQv6z9u3Rg3XkjiEWSJEmaOH3usnJiko2A3dqqi6vqN6MNS5IkSZoMcybkSRYBJwKX0U1X2T7JIVX1lZFGJkmSJE2APlNW3gI8oaouBkiyG/Axuh8JkiRJkrQG+txlZcPpZBygqn4AbDi6kCRJkqTJ0WeE/LwkHwA+3Jafyx0v8JQkSZJ0F/VJyF8MHAG8hG4O+VeAd48yKEmSJGlS9LnLyi1J3llVb02yGbBFVfnDQJIkSdI8mHMOeZI3ANckeQ3wJeArSf5+5JFJkiRJE6DPRZ1/AuxI9wNBTwB+F3hen8aT7J/k4iTLkhw1w/YkObZtvyDJXnPVTfLmJN9v5U9Psnlbv1OSm5Oc3x7H9YlRkiRJGqc+Cfkvq+oXwJeq6udVdQNw81yVkiwA3gUcAOwOHJRk96FiBwC7tsdhwHt61P088OCqegjwA+DogfYuqao92+PwHscmSZIkjVWfizq/BlBVTwNIch/g6h719gGWVdWlrd4pwGLgooEyi4GTqqqAs5NsnmRrYKdV1a2qzw3UPxt4Ro9Y1jlvWfmP89zi4+a5PUmSJK0NfS7qfMnQ8vV0U1fmsi1w+cDycmDfHmW27VkX4AXAxweWd07yLeAG4FVV9dXhCkkOoxuNZ+HChUxNTfU4lPm1YsUK2O3AeW1zHMeh2a1YscJ+mQD282SwnyeD/bz+W1f7eM6EPMlfz7S+qt46V9WZqvUsM2fdJK8EVgIfbauuBHaoqmuTPAz4VJI92hSbwbiPB44H2HvvvWvRokVzHMb8m5qaYsHSU+a1zUce9KV5bU9rbmpqinG8vrR22c+TwX6eDPbz+m9d7eM+U1ZeDVwGnL6abS8Hth9Y3g64omeZjWarm+QQ4CnAY9t0F9qtGG9pz5cmuQTYDThvNeOWJEmS1po+F3XuQnch5WOB/66q11XV63rUOxfYNcnOSTYCDgSWDJVZAhzc7rayH3B9VV05W90k+wMvB55WVb+cbijJVu1iUJLsQneh6KU94pQkSZLGZs6EvKquq6qX0SXFz0zyn0ke3qPeSuBI4Ezge8CpVXVhksOTTN8B5Qy6pHkZ8D7gL2ar2+q8E9gM+PzQ7Q0fBVyQ5NvAJ4HDq+q6uU+BJEmSND595pB/htvnbwfYge7uJgvmqltVZ9Al3YPrjht4XsARfeu29Q9YRfnTgNPmikmSJElal/SZQ/4vI49CkiRJmlB9EvLvjDwKSZIkaUL1ScivBH7CHW9FWHQXe0qSJElaA30S8ouq6vdGHokkSZI0gfok5PdJspjuHt9X0CXoK0cbliRJkjQZ+iTkZwF/AmwCbAPsmOTPquo/RhqZJEmSNAHmTMir6tDB5SQPAD4FmJBLkiRJa6jPL3XeQVUtAx4/glgkSZKkidPnh4E2Bl4I7AFsPLDpBaMKSpIkSZoUfUbIPwz8H+CJdPPJtwNuHGVQkiRJ0qTok5A/oKr+Hripqk4Engz87mjDkiRJkiZDn4T8N+3fXyR5MHAfYKeRRSRJkiRNkD63PTw+yX2BvweWAPcCXj3SqCRJkqQJ0ee2h+9vT88CdhltOJIkSdJk6XOXlRlHw6vq9fMfjiRJkjRZ+swhPwrYH/g1cNPAQ5IkSdIa6jOHfBvgucBTge8DJ1TVBSONSpIkSZoQc46QV9UvqupdwEHAJsD756giSZIkqac+c8ifABwM3AM4GThi1EFJkiRJk6LPHPL/BH4H2Bg4FPi3JEtGGpUkSZI0IfrMIX/0yKOQJEmSJlSf+5CfleT/APsABZxbVVeNPDJJkiRpAsw5ZSXJi4BzgD8GngGcneQFow5MkiRJmgR9pqy8DPi9qroWIMlvA18DThhlYJIkSdIk6HNR53LgxoHlG4HLRxOOJEmSNFn6jJD/BPhGkk/TzSFfDJyT5K8BquqtI4xPkiRJWq/1ScgvaY9pn27/bjb/4UiSJEmTpc9dVl4HkGSzbrFWjDwqSZIkaUL0ucvKg5N8C/gucGGSpUn2GH1okiRJ0vqvz0WdxwN/XVU7VtWOwN8A7xttWJIkSdJk6JOQb1pVX55eqKopYNORRSRJkiRNkD4XdV6a5O+BD7fl5wE/Gl1IkiRJ0uToM0L+AmAr4N+A09vzQ0cZlCRJkjQp+txl5efAS9ZCLJIkSdLE6XOXlS8n+dLwo0/jSfZPcnGSZUmOmmF7khzbtl+QZK+56iZ5c5Lvt/KnJ9l8YNvRrfzFSZ7YJ0ZJkiRpnPrMIf9bIMBHgOf2bTjJAuBdwOOB5cC5SZZU1UUDxQ4Adm2PfYH3APvOUffzwNFVtTLJPwFHAy9PsjtwILAHsA3whSS7VdWtfWOWJEmS1rY+U1aWAiS5efp5T/sAy6rq0lb/FGAxMJiQLwZOqqoCzk6yeZKtgZ1WVbeqPjdQ/2zgGQNtnVJVtwA/SrKsxfD11YhZkiRJWqv6jJBPq9Vse1vg8oHl5XSj4HOV2bZnXeguOP34QFtnz9DWHSQ5DDgMYOHChUxNTc1xGPNvxYoVsNuB89rmOI5Ds1uxYoX9MgHs58lgP08G+3n9t6728ZwJeZIb6ZLxeya5gW76SlXVveeqOsO64aR+VWXmrJvklcBK4KOrsT+q6ni6Hzti7733rkWLFs1QbbSmpqZYsPSUeW3zkQf1mtavtWhqaopxvL60dtnPk8F+ngz28/pvXe3jPlNWNruLbS8Hth9Y3g64omeZjWarm+QQ4CnAY9t0l777kyRJktYpfe5DfledC+yaZOckG9FdcLlkqMwS4OB2t5X9gOur6srZ6ibZH3g58LSq+uVQWwcmuUeSnekuFD1nhMcnSZIkrbHVmUO+WtpdUI4EzgQWACdU1YVJDm/bjwPOAJ4ELAN+SfvBoVXVbU2/E7gH8PkkAGdX1eGt7VPpLhpdCRzhHVYkSZK0rhtZQg5QVWfQJd2D644beF7AEX3rtvUPmGV/xwDH3NV4JUmSpLVtlFNWJEmSJM1htRPyJN9rjyNHEZAkSZI0SVZ7ykpVPSjJbwP7jSAeSZIkaaKsVkKeZFvgvlX1XeCzowlJkiRJmhxzTllJ8uYkV7cf4vkccHKSt40+NEmSJGn912eE/P8CDwYuBrYGfgNcMMqgJEmSpEnR56LOG6rqauCyqvpVu7f3LSOOS5IkSZoIfUbIfyfJBcAD2r8BdhltWJIkSdJk6JOQP2jkUUiSJEkTas4pK1X1Y2Bz4KntsXlbJ0mSJGkN9bnLykuBjwL3a4+PJPnLUQcmSZIkTYI+U1ZeCOxbVTcBJPkn4OvAO0YZmCRJkjQJ+txlJcCtA8u3tnWSJEmS1lCfEfIPAt9IcnpbfjrwgZFFJEmSJE2QORPyqnprkingD+lGxg+tqm+NOjBJkiRpEsyZkCc5vqoOA765FuKRJEmSJkqfOeR7jzwKSZIkaUL1mUO+XZJjh1dW1UtGEI8kSZI0Ufok5DcDS0cdiCRJkjSJ+iTk11XViSOPRJIkSZpAfeaQm4xLkiRJI9InIf9xkvtMLyTZPMnTRxeSJEmSNDn6JOSvqarrpxeq6hfAa0YWkSRJkjRB+iTkM5XpM/dckiRJ0hz6JOTnJXlrkvsn2SXJ2/CuK5IkSdK86JOQ/yXwa+DjwKnAr4AjRhmUJEmSNCnmnHpSVTcBRw2uS7IQuGlUQUmSJEmTYs4R8iQfSJKB5T8DvjzSqCRJkqQJ0WfKyg+BJUkemuRLwL7AH4w2LEmSJGky9Jmy8qYkBwPfAJ5XVZ8cfViSJEnSZJgzIU/y1+3pl4F/SLIDQFW9dZSBSZIkSZOgz/3EN2v/nt0em81SVpIkSdJq6DNl5XUASTZtd1yRJEmSNE/63GXl95NcBHyvLT80ybv7NJ5k/yQXJ1mW5KgZtifJsW37BUn2mqtukmcmuTDJbUn2Hli/U5Kbk5zfHsf1iVGSJEkapz53WflX4InAtQBV9W3gUXNVSrIAeBdwALA7cFCS3YeKHQDs2h6HAe/pUfe7wB8DX5lht5dU1Z7tcXiPY5MkSZLGqk9CTlVdPrTq1h7V9gGWVdWlVfVr4BRg8VCZxcBJ1Tkb2DzJ1rPVrarvVdXFfeKWJEmS1nV9EvLLk/wBUEk2SvK3tOkrc9gWGEzkl7d1fcr0qTuTnZN8K8lZSR7Zo7wkSZI0Vn3usnI48Ha6hHg58DngiB71MsO66lmmT91hVwI7VNW1SR4GfCrJHlV1wx12mBxGNz2GhQsXMjU1NUez82/FihWw24Hz2uY4jkOzW7Fihf0yAeznyWA/Twb7ef23rvZxn4R8h6p67l1oezmw/cDydsAVPcts1KPuHVTVLcAt7fnSJJcAuwHnDZU7HjgeYO+9965Fixb1O5p5NDU1xYKlp8xrm4886Evz2p7W3NTUFON4fWntsp8ng/08Gezn9d+62sd9pqy8/y62fS6wa5Kdk2wEHAgsGSqzBDi43W1lP+D6qrqyZ907SLJVuxiUJLvQXSh66V2MXZIkSVor+oyQb5DkvgxNI6mq62arVFUrkxwJnAksAE6oqguTHN62HwecATwJWAb8Ejh0troASf4v8A5gK+CzSc6vqifS3fnl9UlW0l10evhcMUqSJEnj1ichfyCwlDsm5AXsMlfFqjqDLukeXHfcwPNiFfPRZ6rb1p8OnD7D+tOA0+aKSZIkSVqX9EnIL6qq3xt5JFozJz97ftt7zsfntz1JkiTNqNd9yCVJkiSNRp+E/PdHHoUkSZI0oeZMyKvqV2sjEEmSJGkSOWVFkiRJGiMTckmSJGmM5kzIk2yX5PQk1yT5aZLTkmy3NoKTJEmS1nd9Rsg/SPcrmVsD2wKfaeskSZIkraE+CflWVfXBqlrZHh+i+5VMSZIkSWuoT0L+syTPS7KgPZ4HXDvqwCRJkqRJ0CchfwHwLOAq4ErgGW2dJEmSpDW0QY8yW1bV00YeiSRJkjSB+oyQv3/kUUiSJEkTqs8I+QZJ7gtkcGVVXTeakCRJkqTJ0SchfyCwlDsm5AXsMpKIJEmSpAnSJyG/qKp+b+SRSJIkSROozxxySZIkSSPSJyH//ZFHIUmSJE2oPgn5Z5JsPr2Q5L5JzhxdSJIkSdLk6JOQb1VVv5heqKqfA/cbWUSSJEnSBOmTkN+aZIfphSQ70t1lRZIkSdIa6nOXlVcC/5XkrLb8KOCw0YUkSZIkTY45E/Kq+s8kewH70d2L/P9V1c9GHpkkSZI0AeacspIkwP7AXlX1GeCeSfYZeWSSJEnSBOgzZeXdwG3AY4DXAzcCpwEPH2FcWk1f/eE189re3xzzBc555ePmtU1JkiTdWZ+EfN+q2ivJt6C7y0qSjUYclyRJkjQR+txl5TdJFtDurJJkK7oRc0mSJElrqE9CfixwOnC/JMcA/wX840ijkiRJkiZEn7usfDTJUuCxdHdZeXpVfW/kkUmSJEkTYM6EPMkWwNXAxwbXVdV1owxMkiRJmgR9LupcSjd/PMDWwJVteZcRxiVJkiRNhD5TVnaefp7kW1X1e6MNSZIkSZocfS7qBKDd6tDbHUqSJEnzqM8c8s+0pw8CTh5tOJIkSdJk6TNC/i/APwOPr6pXr07jSfZPcnGSZUmOmmF7khzbtl+QZK+56iZ5ZpILk9yWZO+h9o5u5S9O8sTViVWSJEkahz4XdX5n+km74woAc91lpf2Y0LuAxwPLgXOTLKmqiwaKHQDs2h77Au8B9p2j7neBPwbeO7S/3YEDgT2AbYAvJNmtqm7tcYySJEnSWPRJyH8G/BS4me5OK9DvLiv7AMuq6lKAJKcAi4HBhHwxcFJVFXB2ks2TbA3stKq60/dAT8KQxcApVXUL8KMky1oMX+9xjJIkSdJY9EnIDwP+HPgQ8N6qWtmz7W2ByweWl9ONgs9VZtuedWfa39kztHUHSQ6jOyYWLlzI1NTUHM3OvxUrVsBuB671/a6OF+TmsZyb9cmKFSs8hxPAfp4M9vNksJ/Xf+tqH/e57eH7k3wYOAL4WpK3V9VHe7R9pyFsupH1PmX61L0r+6OqjgeOB9h7771r0aJFczQ7/6ampliw9JS1vt/V8foNXsE5By4adxh3a1NTU4zj9aW1y36eDPbzZLCf13/rah/PeVFnkj8GngxcRjfH++VJvt2j7eXA9gPL2wFX9CzTp+5d2Z8kSZK0TukzZeWpQ8tLe7Z9LrBrkp2Bn9BdcPmcoTJLgCPbHPF9geur6sok1/SoO2wJcHKSt9Jd1LkrcE7PWCVJkqSx6DNl5dC70nBVrUxyJHAmsAA4oaouTHJ4234ccAbwJGAZ8Evg0NnqAiT5v8A7gK2AzyY5v6qe2No+le6i0ZXAEd5hRZIkSeu6Pj8MtGSm9VX1tLnqVtUZdEn34LrjBp4X3dz0XnXb+tOB01dR5xjgmLnikiRJktYVfaasPAh40agDkSRJkiZRn4T8xqo6a+SRSJIkSRNozrusAA9N8oskVyX5ZpJ3JNly5JFJkiRJE2DOhLyqFgBbAPcHng1cBZw44rgkSZKkidBnhJyquq2qbqqqH7YLJ/9zxHFJkiRJE6HPHHKSPA14VFs8q6reMbqQJEmSpMnR55c63wi8lO7+3hcBL2nrJEmSJK2hPiPkTwb2rKrbAJKcCHwLOHqUgUmSJEmToNcccmDzgef3GUEckiRJ0kTqM0L+RuBbSb4MhG4u+StGGpUkSZI0IeZMyKvqY0mmgIfTJeQvr6qrRh2YJEmSNAlWOWUlyZOnn1fVlVW1pKo+DdyUxLusSJIkSfNgtjnkb0/ywsEVSZ4DXABcPdKoJEmSpAkx25SVRwKfTbItcArwbuDXwOOq6pK1EZwkSZK0vlvlCHlVXQn8EV1ifgHw/qp6ksm4JEmSNH9mve1hVd0IHACcCjwnycZrJSpJkiRpQqxyykqSG4GaXgQ2Ba5LcitQVXXvtRCfJEmStF5bZUJeVZutzUAkSZKkSdTnh4E0gd6y8h/h5PfNb6PP+fj8tidJkrQemHUOuSRJkqTRMiGXJEmSxsiEXJIkSRojE3JJkiRpjEzIJUmSpDEyIZckSZLGyIRckiRJGiMTckmSJGmMTMglSZKkMTIhlyRJksbIhFySJEkaIxNySZIkaYxMyCVJkqQxMiGXJEmSxsiEXJIkSRqjkSbkSfZPcnGSZUmOmmF7khzbtl+QZK+56ibZIsnnk/yw/Xvftn6nJDcnOb89jhvlsUmSJEnzYWQJeZIFwLuAA4DdgYOS7D5U7ABg1/Y4DHhPj7pHAV+sql2BL7blaZdU1Z7tcfhojkySJEmaP6McId8HWFZVl1bVr4FTgMVDZRYDJ1XnbGDzJFvPUXcxcGJ7fiLw9BEegyRJkjRSG4yw7W2ByweWlwP79iiz7Rx1F1bVlQBVdWWS+w2U2znJt4AbgFdV1VeHg0pyGN1oPAsXLmRqamo1D2vNrVixAnY7cK3vd3VN3WOeXx5jONfjtGLFirG8vrR22c+TwX6eDPbz+m9d7eNRJuSZYV31LNOn7rArgR2q6tokDwM+lWSPqrrhDo1UHQ8cD7D33nvXokWL5mh2/k1NTbFg6Slrfb+r65G7bjW/DS76+Py2t46bmppiHK8vrV3282SwnyeD/bz+W1f7eJRTVpYD2w8sbwdc0bPMbHV/2qa10P69GqCqbqmqa9vzpcAlwG7zciSSJEnSiIwyIT8X2DXJzkk2Ag4ElgyVWQIc3O62sh9wfZuOMlvdJcAh7fkhwKcBkmzVLgYlyS50F4peOrrDkyRJktbcyKasVNXKJEcCZwILgBOq6sIkh7ftxwFnAE8ClgG/BA6drW5r+k3AqUleCPwP8My2/lHA65OsBG4FDq+q60Z1fJPgqz+8Zl7be+S8tiZJkrR+GOUccqrqDLqke3DdcQPPCziib922/lrgsTOsPw04bQ1DliRJktYqf6lTkiRJGiMTckmSJGmMTMglSZKkMRrpHHLpDk5+9vy295zJuq+5JElaPzlCLkmSJI2RCbkkSZI0RibkkiRJ0hiZkEuSJEljZEIuSZIkjZEJuSRJkjRGJuSSJEnSGJmQS5IkSWNkQi5JkiSNkQm5JEmSNEYm5JIkSdIYmZBLkiRJY7TBuAOQ7rKTnz2/7T3n4/PbniRJUg8m5FprvvrDa+a1vUfuutW8tidJkjQOTlmRJEmSxsiEXJIkSRojE3JJkiRpjEzIJUmSpDEyIZckSZLGyLusSNPm+zaKGz8RWDS/bUqSpPWOI+SSJEnSGDlCrrst72suSZLWBybk0ij5a6KSJGkOTlmRJEmSxsiEXJIkSRojE3JJkiRpjJxDLjXzfZHoit1Wzmt7gHPSJUlaDzlCLkmSJI2RI+TSCK3zt2Z0xF2SpLEbaUKeZH/g7cAC4P1V9aah7WnbnwT8Enh+VX1ztrpJtgA+DuwEXAY8q6p+3rYdDbwQuBV4SVWdOcrjkzRkvhN8MMmXpAm2zzFfmNf2/vkR6+ZY9MiiSrIAeBfweGA5cG6SJVV10UCxA4Bd22Nf4D3AvnPUPQr4YlW9KclRbfnlSXYHDgT2ALYBvpBkt6q6dVTHKK1t8z3iPgqO4kuStHpG+TFhH2BZVV0KkOQUYDEwmJAvBk6qqgLOTrJ5kq3pRr9XVXcxsKjVPxGYAl7e1p9SVbcAP0qyrMXw9REeo6QhEzdNZ+Mnwsnvmd82/dAgSRNllAn5tsDlA8vL6UbB5yqz7Rx1F1bVlQBVdWWS+w20dfYMbUm6G1vXvxVYsdvK+Y/xdY+Z3/buBub7g9e898nvPm9eP3it66/rUZj3D9cjsCKP5auve/28tbfOv67vBt4yz+3dyqvnucX5McqEPDOsq55l+tS9K/sjyWHAYW1xRZKL52h3FLYEfjaG/Wqt+rL9PBHs58lgP0+GU+3n9d5Y/5Z3XNWGUSbky4HtB5a3A67oWWajWer+NMnWbXR8a+Dq1dgfVXU8cPzqHcr8SnJeVe09zhg0evbzZLCfJ4P9PBns5/XfutrHo7wP+bnArkl2TrIR3QWXS4bKLAEOTmc/4Po2HWW2ukuAQ9rzQ4BPD6w/MMk9kuxMd6HoOaM6OEmSJGk+jGyEvKpWJjkSOJPu1oUnVNWFSQ5v248DzqC75eEyutseHjpb3db0m4BTk7wQ+B/gma3OhUlOpbvwcyVwhHdYkSRJ0rou3Q1OtDYlOaxNndF6zH6eDPbzZLCfJ4P9vP5bV/vYhFySJEkao1HOIZckSZI0BxPytSjJ/kkuTrKs/cqo7kaSnJDk6iTfHVi3RZLPJ/lh+/e+A9uObn19cZInDqx/WJLvtG3HJpnplp0akyTbJ/lyku8luTDJS9t6+3o9kmTjJOck+Xbr59e19fbzeibJgiTfSvLvbdk+Xg8luaz10flJzmvr7jZ9bUK+liRZALwLOADYHTgoye7jjUqr6UPA/kPrjgK+WFW7Al9sy7S+PRDYo9V5d3sNALyH7l74u7bHcJsar5XA31TVg4D9gCNaf9rX65dbgMdU1UOBPYH9292+7Of1z0uB7w0s28frr0dX1Z4DtzW82/S1Cfnasw+wrKourapfA6cAi8cck1ZDVX0FuG5o9WLgxPb8RODpA+tPqapbqupHdHcS2ifdvfPvXVVfr+4CjpMG6mgdUFVXVtU32/Mb6f4j3xb7er1SnRVtccP2KOzn9UqS7YAnA+8fWG0fT467TV+bkK892wKXDywvb+t097aw3Tuf9u/92vpV9fe27fnweq2DkuwE/B7wDezr9U6bynA+3Q/Mfb6q7Of1z78CfwfcNrDOPl4/FfC5JEvT/So73I36epS/1Kk7mmkOkre4WX+tqr99HdxNJLkXcBrwV1V1wyzTCO3ru6n2WxV7JtkcOD3Jg2cpbj/fzSR5CnB1VS1NsqhPlRnW2cd3H4+oqiuS3A/4fJLvz1J2netrR8jXnuXA9gPL2wFXjCkWzZ+ftq+4aP9e3davqr+Xt+fD67UOSbIhXTL+0ar6t7bavl5PVdUvgCm6uaL28/rjEcDTklxGN030MUk+gn28XqqqK9q/VwOn000Vvtv0tQn52nMusGuSnZNsRHcxwZIxx6Q1twQ4pD0/BPj0wPoDk9wjyc50F4ac074yuzHJfu3K7YMH6mgd0PrlA8D3quqtA5vs6/VIkq3ayDhJNgEeB3wf+3m9UVVHV9V2VbUT3f+5X6qq52Efr3eSbJpks+nnwBOA73I36munrKwlVbUyyZHAmcAC4ISqunDMYWk1JPkYsAjYMsly4DXAm4BTk7wQ+B/gmQBVdWGSU4GL6O7acUT7ehzgxXR3bNkE+I/20LrjEcCfAt9p84sBXoF9vb7ZGjix3Vnht4BTq+rfk3wd+3l959/y+mch3bQz6HLbk6vqP5Ocy92kr/2lTkmSJGmMnLIiSZIkjZEJuSRJkjRGJuSSJEnSGJmQS5IkSWNkQi5JkiSNkQm5pImTZMXA862TXJLkqeOMSZI0uUzIJU2s9kMSZwD/VFWfGXc8kqTJZEIuaSIl2RD4N2BJVR0/sP6gJN9J8t0k/zRU59Yk5ydZluTf27oPJXlGe/6iJJVkyySLpsu0bZcl2bI9f16Sc1pb720/TkOS/ZN8M8m3k3wxySatzPlJft3iOj/J3m2/P2pxXpDkwa2NPZOc3dadnuS+Mxz7wrbt2+3xB0l2SvLd6XOT5NIk7xw4xuUDcb64HedO7XFzi+vSJP/SyiTJm1t830ny7IH9L0pyfatzVZK/besfm+RbrfwJSe4xcO6+k+T7ST7Xfolv+JhmLZPk2QN9N73vM9q2JyT5ejv3n0hyr8E+S3KvJP+d5Alt/cOTfK2du3OSbJbky63NFUkubs+flu4XBE9Icm47tsVzvzolTRoTckmT6gTgj4CPTa9Isg3wT8BjgD2Bhyd5etu2ALipqvYEXjTcWJKNgcOBq9uq24DMUO5BwLOBR7S2bgWem2Qr4H3An1TVQ4FnVtXNVbVnK3cF8Oi2fF5r7mVV9WDgKy1mgJOAl1fVQ4Dv0P2i7LBjgbPafvYChn81+DBgxdC6nwBPbM8XA8sGtl3SYvx94Plt3R/TncOH0v0s/ZuTbN22LWj73xM4rp2Xjel+He/ZVfW7dL+29+KBfTwa2IPuF/nuP8MxzVqmqj4+0HdfbefxSe1D0quAx1XVXsB5wF8PVN0Q+ATwnqr6XJKNgI8DL23n73HAzVX16Nb+ecBzW/tLgFfS/WT7w1t8b57pA4WkyWZCLmkSbQpsQZc8vmtg/cOBqaq6pqpWAh8FHtW2bQL8apY2jwBOBG5uy8uBB7VEc9BjgYcB5yY5vy3vAuwHfKWqfgRQVdf1OI43J/kh8DTgE0nuA2xeVWe17ScOxD/oMcB72n5urarrpzckuSdw6PT2AR8G/rSNxP8QuGVg2/3bsfwAeHtb94fAx1r7PwXOoju/MPO5fCDwo6r6wSpi/zJwOfBTug8aM+lTZth+wO7Af7djOATYcWD7+4Ctq+ojA3FeWVXnAlTVDe21sipPAI5qbU8BGwM79IxN0oQwIZc0iW4BnlVVJwO/SfLctv5OI9oDtqEbpZ7JvYGDgPdOr6iqS4GTgW+2ZGybgX2cOD3yXVUPrKrXtvW1msfxsqraFXg98LrVrLsqfwUcz+0fLKZdRTda/DLgg0PbpkfItwYOSrI9q38uZysP3ejytnTJ9kFrUGZYgM8P9MfuVfXCge0/BL6d5AUD5Venn0L3rcd0+ztU1fdWo76kCWBCLmkSrayqm9rzI4Fj2ujyN4A/avOGF9AlddOjzc8C/nsV7f0/4Niq+vXgyqp6VUvw9uT2BPSLwDOS3A8gyRZJdgS+3va98/T61TieG4At20j3z5M8sq3/04H4B32RNh0kyYIk927r7wM8nW46z0w+CNyvqr65iu230E3BuS/dNJpnt/a3ohvtPqed1z/mzufy+8BOSR6wqtirqoAbgS1Xsf9eZYacDTxier9J7plkt4Htx9BNYfm7JAtbnNskeXgrv1mSDWZp/0zgL5Oklf+9nnFJmiCzvYlI0nqvqpYl+SDwj1V1RJKj6aY+BDijqj6d5CXAI+imM8wkwEdWsW14fxcleRXwuSS/BfwGOKKqzk5yGPBvbf3VwOPnaO7Nra3i9nnthwDHtaknl9JNPxn2UuD4JC+kS6BfDFwJbAf8bVWtbPnjcOyfBT47Q3vTU1buQTfafEGS79DNKf92i+/vquqqJCfTjTqfNtT2r5IcSjf1ZgPgXNr88ubLSYpu9PsVqzgffcoMH9M1SZ4PfGz6IlK6OeU/GChzbZLXA++oqme1C1TfkWQTum8SHsed59xPewPwr8AFLSm/DHhKn9gkTY50gwmSJEmSxsEpK5IkSdIYmZBLkiRJY2RCLkmSJI2RCbkkSZI0RibkkiRJ0hiZkEuSJEljZEIuSZIkjZEJuSRJkjRG/x/6Ei2OD/oPwQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.query('toxic == 1')['length'].plot(kind = 'hist', bins = 30, figsize = (12, 6), alpha = 0.9, density = True)\n",
    "data.query('toxic == 0')['length'].plot(kind = 'hist', bins = 30, grid = True,  alpha = 0.7, density = True)\n",
    "\n",
    "plt.title('Распределение количества текстов в зависимоти от их размеров')\n",
    "plt.xlabel('Количество символов в тексте')\n",
    "plt.ylabel('Количесто текстов, нормализованное')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По графикам видим, что токсичные и нейтральные тексты особо не отличаются друг от друга. Интересно было посмотреть на распределение количества текстов в зависимости от отношения числа слов, набранных прописными буквами, к общему количеству слов в тексте. Однако, иногда комментарии могут состоять из текстов без пробелов или, наоборот, с большим количеством пробелов, поэтому будет считать не по отношению к общему количеству слов, а по отошению к общему количеству символов в тексте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['caps'] = data['text'].apply(lambda x: len(re.findall(r'[A-Z]{2,}', x))) / data['text'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12, 6))\n",
    "data.query('toxic == 0 & caps < 1')['caps'].plot(x = 'caps', kind = 'hist', \n",
    "                                                 bins = 30, alpha = 0.6, \n",
    "                                                 color = 'green',  density = True)\n",
    "\n",
    "data.query('toxic == 1 & caps < 1')['caps'].plot(x = 'caps', kind = 'hist', \n",
    "                                                 bins = 30, alpha = 0.5, \n",
    "                                                 color = 'blue', density = True)\n",
    "\n",
    "plt.title('Распределение количества текстов в зависимости от коэффициента \"прописных\" слов')\n",
    "plt.xlabel('Соотношение количества слов, набранных прописными буквами к общему количеству символов в тексте')\n",
    "plt.ylabel('Количесто текстов, нормализованное')\n",
    "\n",
    "plt.ylim(0, 10)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По графику видно, что ориентировочно до значения коэффициента \"прописных\" слов =0,05 токсичные тексты не отличаются от нейтральных текстов, но далее, с ростом коэффициента (количества \"прописных\" слов) нейтральных текстов становится гораздо меньше токсичных. Причем со значения =0,125 наблюдается существенный рост токсичных текстов. Таким образом, наше предположение подтвердилось, оставим данный коэффициент в качестве нового признака."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Восклицательные знаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Второе предположение является продолжением первого: для усиления своего токсичного комментария пользователь употребляет большое количество восклицательных знаков. Проверим наше предположение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ex_point'] = data['text'].apply(lambda x: \n",
    "                                      len(re.findall(r'[!]', x))) / data['text'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12, 6))\n",
    "data.query('toxic == 0')['ex_point'].plot(kind = 'hist', \n",
    "                                                 bins = 30, alpha = 0.6, \n",
    "                                                 color = 'green',  density = True)\n",
    "\n",
    "data.query('toxic == 1')['ex_point'].plot(kind = 'hist', \n",
    "                                                 bins = 30, alpha = 0.5, \n",
    "                                                 color = 'blue', density = True)\n",
    "\n",
    "plt.title('Распределение количества текстов в зависимости от количества восклицательных знаков в тексте')\n",
    "plt.xlabel('Соотношение количества воскицательных знаков к общему количеству символов в тексте')\n",
    "plt.ylabel('Количесто текстов, нормализованное')\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По графику распределения также видим, что у токсичных текстов \"хвост\" с большим количеством восклицательных знаков больше чем у нейтральных текстов. После значения коэффициента =0,2 нейтральных текстов практически не осталось. Наше предположение имеет право на существование, также оставим значения данного коэффициента в качестве нового признака."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположения о большем количестве специальных символов и пробелов, а также использовании более коротких слов в токсичных текстах не нашли подтверждения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исключим все лишние символы из текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: ' '.join(re.sub(r\"\"\"[^a-z'A-Z]\"\"\", ' ', x).split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизируем тексты "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.tokenize.wordpunct_tokenize\n",
    "wnl = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_lemmatize(text):\n",
    "    text = text.lower()\n",
    "    tokens_lemmatized = ' '.join([wnl.lemmatize(token) for token in tokenizer(text)])\n",
    "    return tokens_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159571/159571 [00:49<00:00, 3231.44it/s]\n"
     ]
    }
   ],
   "source": [
    "data['text_lemm'] = Parallel(n_jobs=-1)(delayed(func_lemmatize)(item) for item in tqdm(data['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>length</th>\n",
       "      <th>caps</th>\n",
       "      <th>ex_point</th>\n",
       "      <th>text_lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18671</th>\n",
       "      <td>Notability of James Cunningham developer A tag has been placed on James Cunningham developer requesting that it be speedily deleted from Wikipedia This has been done because the article appears to be about a person group of people band club company or web content but it does not indicate how or why the subject is notable that is why an article about that subject should be included in an encyclopedia Under the criteria for speedy deletion articles that do not assert the subject's importance or significance may be deleted at any time Please see the guidelines for what is generally accepted as notable If you think that you can assert the notability of the subject you may contest the deletion by adding to the top of the page just below the existing speedy deletion or db tag coupled with adding a note on the article's talk page explaining your position but be aware that once tagged for speedy deletion if the article meets the criterion it may be deleted without delay Please do not remove the speedy deletion tag yourself but don't hesitate to add information to the article that would confirm the subject's notability under Wikipedia guidelines For guidelines on specific types of articles you may want to check out our criteria for biographies for web sites for bands or for companies Feel free to leave a note on my talk page if you have any questions about this</td>\n",
       "      <td>0</td>\n",
       "      <td>1419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>notability of james cunningham developer a tag ha been placed on james cunningham developer requesting that it be speedily deleted from wikipedia this ha been done because the article appears to be about a person group of people band club company or web content but it doe not indicate how or why the subject is notable that is why an article about that subject should be included in an encyclopedia under the criterion for speedy deletion article that do not assert the subject ' s importance or significance may be deleted at any time please see the guideline for what is generally accepted a notable if you think that you can assert the notability of the subject you may contest the deletion by adding to the top of the page just below the existing speedy deletion or db tag coupled with adding a note on the article ' s talk page explaining your position but be aware that once tagged for speedy deletion if the article meet the criterion it may be deleted without delay please do not remove the speedy deletion tag yourself but don ' t hesitate to add information to the article that would confirm the subject ' s notability under wikipedia guideline for guideline on specific type of article you may want to check out our criterion for biography for web site for band or for company feel free to leave a note on my talk page if you have any question about this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46012</th>\n",
       "      <td>The Tireless Contributor Barnstar I hereby award you this barnstar for your tireless invaluable work here Keep up the good work Regards nd</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006711</td>\n",
       "      <td>the tireless contributor barnstar i hereby award you this barnstar for your tireless invaluable work here keep up the good work regard nd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124674</th>\n",
       "      <td>I was talking to you</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>i wa talking to you</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  text  \\\n",
       "18671   Notability of James Cunningham developer A tag has been placed on James Cunningham developer requesting that it be speedily deleted from Wikipedia This has been done because the article appears to be about a person group of people band club company or web content but it does not indicate how or why the subject is notable that is why an article about that subject should be included in an encyclopedia Under the criteria for speedy deletion articles that do not assert the subject's importance or significance may be deleted at any time Please see the guidelines for what is generally accepted as notable If you think that you can assert the notability of the subject you may contest the deletion by adding to the top of the page just below the existing speedy deletion or db tag coupled with adding a note on the article's talk page explaining your position but be aware that once tagged for speedy deletion if the article meets the criterion it may be deleted without delay Please do not remove the speedy deletion tag yourself but don't hesitate to add information to the article that would confirm the subject's notability under Wikipedia guidelines For guidelines on specific types of articles you may want to check out our criteria for biographies for web sites for bands or for companies Feel free to leave a note on my talk page if you have any questions about this   \n",
       "46012   The Tireless Contributor Barnstar I hereby award you this barnstar for your tireless invaluable work here Keep up the good work Regards nd                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "124674  I was talking to you                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "\n",
       "        toxic  length  caps  ex_point  \\\n",
       "18671   0      1419    0.0   0.000000   \n",
       "46012   0      149     0.0   0.006711   \n",
       "124674  0      21      0.0   0.000000   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     text_lemm  \n",
       "18671   notability of james cunningham developer a tag ha been placed on james cunningham developer requesting that it be speedily deleted from wikipedia this ha been done because the article appears to be about a person group of people band club company or web content but it doe not indicate how or why the subject is notable that is why an article about that subject should be included in an encyclopedia under the criterion for speedy deletion article that do not assert the subject ' s importance or significance may be deleted at any time please see the guideline for what is generally accepted a notable if you think that you can assert the notability of the subject you may contest the deletion by adding to the top of the page just below the existing speedy deletion or db tag coupled with adding a note on the article ' s talk page explaining your position but be aware that once tagged for speedy deletion if the article meet the criterion it may be deleted without delay please do not remove the speedy deletion tag yourself but don ' t hesitate to add information to the article that would confirm the subject ' s notability under wikipedia guideline for guideline on specific type of article you may want to check out our criterion for biography for web site for band or for company feel free to leave a note on my talk page if you have any question about this  \n",
       "46012   the tireless contributor barnstar i hereby award you this barnstar for your tireless invaluable work here keep up the good work regard nd                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "124674  i wa talking to you                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразование в леммы прошло не идеально, остались некоторые слова, для которых не была возвращена исходная форма, к примеру, слова \"making\", \"happening\", \"deleted\". Оставим пока так."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Масштабирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем масштабирование численных признаков, предварительно разбив исходную выборку на тренировочную и тестовую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>length</th>\n",
       "      <th>caps</th>\n",
       "      <th>ex_point</th>\n",
       "      <th>text_lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation Why the edits made under my username Hardcore Metallica Fan were reverted They weren't vandalisms just closure on some GAs after I voted at New York Dolls FAC And please don't remove the template from the talk page since I'm retired now</td>\n",
       "      <td>0</td>\n",
       "      <td>264</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>explanation why the edits made under my username hardcore metallica fan were reverted they weren ' t vandalism just closure on some gas after i voted at new york doll fac and please don ' t remove the template from the talk page since i ' m retired now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww He matches this background colour I'm seemingly stuck with Thanks talk January UTC</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>d ' aww he match this background colour i ' m seemingly stuck with thanks talk january utc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man I'm really not trying to edit war It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page He seems to care more about the formatting than the actual info</td>\n",
       "      <td>0</td>\n",
       "      <td>233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>hey man i ' m really not trying to edit war it ' s just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page he seems to care more about the formatting than the actual info</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>More I can't make any real suggestions on improvement I wondered if the section statistics should be later on or a subsection of types of accidents I think the references may need tidying so that they are all in the exact same format ie date format etc I can do that later on if no one else does first if you have any preferences for formatting style on references or want to do it yourself please let me know There appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up It's listed in the relevant form eg Wikipedia Good article nominations Transport</td>\n",
       "      <td>0</td>\n",
       "      <td>622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>more i can ' t make any real suggestion on improvement i wondered if the section statistic should be later on or a subsection of type of accident i think the reference may need tidying so that they are all in the exact same format ie date format etc i can do that later on if no one else doe first if you have any preference for formatting style on reference or want to do it yourself please let me know there appears to be a backlog on article for review so i guess there may be a delay until a reviewer turn up it ' s listed in the relevant form eg wikipedia good article nomination transport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You sir are my hero Any chance you remember what page that's on</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>you sir are my hero any chance you remember what page that ' s on</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        text  \\\n",
       "0  Explanation Why the edits made under my username Hardcore Metallica Fan were reverted They weren't vandalisms just closure on some GAs after I voted at New York Dolls FAC And please don't remove the template from the talk page since I'm retired now                                                                                                                                                                                                                                                                                                                                                                    \n",
       "1  D'aww He matches this background colour I'm seemingly stuck with Thanks talk January UTC                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "2  Hey man I'm really not trying to edit war It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page He seems to care more about the formatting than the actual info                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "3  More I can't make any real suggestions on improvement I wondered if the section statistics should be later on or a subsection of types of accidents I think the references may need tidying so that they are all in the exact same format ie date format etc I can do that later on if no one else does first if you have any preferences for formatting style on references or want to do it yourself please let me know There appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up It's listed in the relevant form eg Wikipedia Good article nominations Transport   \n",
       "4  You sir are my hero Any chance you remember what page that's on                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "\n",
       "   toxic  length      caps  ex_point  \\\n",
       "0  0      264     0.007576  0.000000   \n",
       "1  0      112     0.008929  0.008929   \n",
       "2  0      233     0.000000  0.000000   \n",
       "3  0      622     0.000000  0.000000   \n",
       "4  0      67      0.000000  0.000000   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            text_lemm  \n",
       "0  explanation why the edits made under my username hardcore metallica fan were reverted they weren ' t vandalism just closure on some gas after i voted at new york doll fac and please don ' t remove the template from the talk page since i ' m retired now                                                                                                                                                                                                                                                                                                                                                        \n",
       "1  d ' aww he match this background colour i ' m seemingly stuck with thanks talk january utc                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "2  hey man i ' m really not trying to edit war it ' s just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page he seems to care more about the formatting than the actual info                                                                                                                                                                                                                                                                                                                                                                           \n",
       "3  more i can ' t make any real suggestion on improvement i wondered if the section statistic should be later on or a subsection of type of accident i think the reference may need tidying so that they are all in the exact same format ie date format etc i can do that later on if no one else doe first if you have any preference for formatting style on reference or want to do it yourself please let me know there appears to be a backlog on article for review so i guess there may be a delay until a reviewer turn up it ' s listed in the relevant form eg wikipedia good article nomination transport  \n",
       "4  you sir are my hero any chance you remember what page that ' s on                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_0, features_test_0, target_train, target_test = train_test_split(data.drop(['toxic', \n",
    "                                'length', 'text'], axis =1), data['toxic'], test_size = 0.3, \n",
    "                                            random_state = 12345, stratify = data['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(features_train_0[['caps', 'ex_point']])\n",
    "features_train_0[['caps', 'ex_point']] = scaler.transform(features_train_0[['caps', 'ex_point']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(features_test_0[['caps', 'ex_point']])\n",
    "features_test_0[['caps', 'ex_point']] = scaler.transform(features_test_0[['caps', 'ex_point']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Включим в наши выборки признак на основе оценки важности слов tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_tfidf(x_train, x_test):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    count_tfidf = TfidfVectorizer(stop_words = stop_words)\n",
    "    \n",
    "    tf_idf_train = count_tfidf.fit_transform(x_train['text_lemm'])\n",
    "    tf_idf_test = count_tfidf.transform(x_test['text_lemm'])\n",
    "    \n",
    "    features_train = sp.sparse.hstack((tf_idf_train, x_train[['caps', 'ex_point']]))\n",
    "    features_test = sp.sparse.hstack((tf_idf_test, x_test[['caps', 'ex_point']]))\n",
    "    \n",
    "    return (features_train, features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test = func_tfidf(features_train_0, features_test_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47872, 127855)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате анализа данных были выявлены некоторые закономерности, которы позволили создать новые признаки для будущих моделей. Такими признаками оказались зависимости целевого признака от наличия в тексте комментария прописных букв и от наличия в тексте восклицательных знаков. Признаки были добавлены в общую талицу признаков.\n",
    "\n",
    "Помимо этого, на данном этапе была проведена лемматизация текстов, удалены лишние символы и стоп-слова. Тексты были преобразованы в матрицу со значениями оценки важности слов в текстах TF-IDF. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим функцию для подбора параметров разрабатываемых моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_score(params, x_train, y_train, type_model):\n",
    "    model = type_model(**params, random_state = 12345)\n",
    "    current_score = cross_val_score(model, x_train, y_train, scoring = 'f1', cv = 3).mean()\n",
    "    \n",
    "    return {'loss': -current_score, 'params': params, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим функцию для тестирования полученных моделей на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_func_model(hyper_param, type_model, \n",
    "                    x_train = features_train, y_train = target_train, \n",
    "                    x_test = features_test, y_test = target_test):\n",
    "    \n",
    "    model = type_model(**hyper_param, random_state = 12345)\n",
    "    model.fit(x_train, y_train)\n",
    "    predicted = model.predict(x_test)\n",
    "    \n",
    "    return f1_score(y_test, predicted) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metric = pd.DataFrame(index = ['f1_train', 'f1_test'], columns = ['Tree'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем поиск с простых моделей. Определим пространство гиперпараметров для классификатора Дерево решений, куда включим параметр class_weight для сбаланисрования классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {'max_depth': hp.choice('max_depth', range(1,20)),\n",
    "        'class_weight' : 'balanced'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [11:13<00:00, 67.39s/trial, best loss: -0.5955198236774559]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn = partial(hyperopt_score, \n",
    "                         x_train = features_train, y_train = target_train, \n",
    "                         type_model = DecisionTreeClassifier), \n",
    "                                                     space = space, algo = tpe.suggest, \n",
    "                                                     max_evals = 10, trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 17}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metric.loc['f1_train', 'Tree'] = round(-trials.results[np.argmin([r['loss'] for r in trials.results])]['loss'], 2)\n",
    "\n",
    "hyper_param = {'max_depth' : trials.results[np.argmin([r['loss'] for r in trials.results])]['params']['max_depth']}\n",
    "hyper_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим модель на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1_train</th>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_test</th>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Tree\n",
       "f1_train  0.6 \n",
       "f1_test   0.63"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metric.loc['f1_test', 'Tree'] = round(test_func_model(hyper_param, DecisionTreeClassifier), 2)\n",
    "model_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для модели DecisionTreeClassifier повышение веса у более редкого класса с помощью гиперпараметра class_weight позволило увеличить значение метрики $f1_{score}$ на 0,2 пункта, но этого все равно недостаточно. При требуемом значениии $f1_{score} > 0,75$, у нас на тестовой выборке получилось $f1_{score} = 0,62$. Этого недостаточно. Попробуем модель логистической регресии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель логистической регресии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state = 12345, solver = 'liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metric.loc['f1_train', 'LR'] = round(cross_val_score(model, features_train, target_train, \n",
    "                                                         scoring = 'f1', cv = 3).mean(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим модель на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tree</th>\n",
       "      <th>LR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1_train</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_test</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Tree    LR\n",
       "f1_train  0.6   0.70\n",
       "f1_test   0.63  0.73"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_param = {'solver' : 'liblinear'}\n",
    "model_metric.loc['f1_test', 'LR'] = round(test_func_model(hyper_param, LogisticRegression), 2)\n",
    "model_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель логистической регрессии показала себя значительно лучше: $f1_{score} = 0,73$ на тестовых данных, что совсем немного не дотягивает до требуемого значения. Попробуем улучшить тренировочную выборку с помощью другого метода устранения дисбаланса классов, увеличив количество строк класса =1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Увеличение выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как ранее было отмечено, в выборке присутствует дисбаланс классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100342\n",
       "1    11357 \n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увеличим количество записей с ответом \"1\" и посмотрим, как это повлияет на модель. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train_zero = target_train[target_train == 0]\n",
    "target_train_one = target_train[target_train == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_zero = features_train_0.loc[target_train_zero.index]\n",
    "features_train_one = features_train_0.loc[target_train_one.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_up = pd.concat([features_train_zero] + [features_train_one] * 2)\n",
    "target_train_up = pd.concat([target_train_zero] + [target_train_one] * 2)\n",
    "\n",
    "features_train_up = shuffle(features_train_up, random_state = 12345)\n",
    "target_train_up = shuffle(target_train_up, random_state = 12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123056, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train_up.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_up, features_test_up = func_tfidf(features_train_up, features_test_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LogisticRegression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим обновленную тренировочную выборку на модели LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state = 12345, solver = 'liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metric.loc['f1_train', 'LR_up'] = round(cross_val_score(model, features_train_up, target_train_up, \n",
    "                                                         scoring = 'f1', cv = 3).mean(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим модель на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tree</th>\n",
       "      <th>LR</th>\n",
       "      <th>LR_up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1_train</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_test</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Tree    LR  LR_up\n",
       "f1_train  0.6   0.70  0.80 \n",
       "f1_test   0.63  0.73  0.78 "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_param = {'solver' : 'liblinear'}\n",
    "model_metric.loc['f1_test', 'LR_up'] = round(test_func_model(hyper_param, \n",
    "                                                             LogisticRegression, \n",
    "                                                             features_train_up, target_train_up, features_test_up), 2)\n",
    "model_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью модели логистической регрессии и увеличенной значениями класа =1 тренировочной выборки удалось получить на тестовой выборке удовлетворительный результат $f1_{score}=0,78$. Посмотим, что покажет DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DecisionTree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [09:40<00:00, 58.03s/trial, best loss: -0.6825631167168913]\n"
     ]
    }
   ],
   "source": [
    "space = {'max_depth': hp.choice('max_depth', range(1,20))}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn = partial(hyperopt_score, \n",
    "                         x_train = features_train_up, y_train = target_train_up, \n",
    "                         type_model = DecisionTreeClassifier), \n",
    "                                                     space = space, algo = tpe.suggest, \n",
    "                                                     max_evals = 10, trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 16}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metric.loc['f1_train', 'Tree_up'] = round(-trials.results[np.argmin([r['loss'] for r in trials.results])]['loss'], 2)\n",
    "\n",
    "hyper_param = {'max_depth' : trials.results[np.argmin([r['loss'] for r in trials.results])]['params']['max_depth']}\n",
    "hyper_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tree</th>\n",
       "      <th>LR</th>\n",
       "      <th>LR_up</th>\n",
       "      <th>Tree_up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1_train</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_test</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Tree    LR  LR_up  Tree_up\n",
       "f1_train  0.6   0.70  0.80   0.68   \n",
       "f1_test   0.63  0.73  0.78   0.64   "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metric.loc['f1_test', 'Tree_up'] = round(test_func_model(hyper_param, DecisionTreeClassifier,  \n",
    "                                                         features_train_up, target_train_up), 2)\n",
    "model_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На результат модели DecisionTreeClassifier увеличение в тренировочной выборке класса =1 никакне повлияло $f1_{score}=0,65$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Уменьшение выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как повлияет на результаты моделей метод устранения дисбаланса с помощью уменьшения в тренровочнй выборке значений класса =0. Напишем функцию для уменьшения тренировочной выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_down_sample(features, target, fraction):\n",
    "    \n",
    "    target_zero = target[target == 0]\n",
    "    target_one = target[target == 1]\n",
    "    \n",
    "    features_zero = features.loc[target_zero.index]\n",
    "    features_one = features.loc[target_one.index]\n",
    "    \n",
    "    features_down = pd.concat([features_zero.sample(frac = fraction, random_state = 12345)] + [features_one])\n",
    "    target_down = pd.concat([target_zero.sample(frac = fraction, random_state = 12345)] + [target_one])\n",
    "    \n",
    "    features_down, target_down = shuffle(features_down, target_down, random_state = 12345)\n",
    "    \n",
    "    return (features_down, target_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_down, target_train_down = func_down_sample(features_train_0, target_train, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_down, features_test_down = func_tfidf(features_train_down, features_test_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LogisticRegression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим обновленную тренировочную выборку на модели LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state = 12345, solver = 'liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metric.loc['f1_train', 'LR_down'] = round(cross_val_score(model, features_train_down, target_train_down, \n",
    "                                                                scoring = 'f1', cv = 3).mean(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим модель на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tree</th>\n",
       "      <th>LR</th>\n",
       "      <th>LR_up</th>\n",
       "      <th>Tree_up</th>\n",
       "      <th>LR_down</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1_train</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_test</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Tree    LR  LR_up  Tree_up  LR_down\n",
       "f1_train  0.6   0.70  0.80   0.68     0.79   \n",
       "f1_test   0.63  0.73  0.78   0.64     0.77   "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_param = {'solver' : 'liblinear'}\n",
    "model_metric.loc['f1_test', 'LR_down'] = round(test_func_model(hyper_param, \n",
    "                                                             LogisticRegression, \n",
    "                                                             features_train_down, target_train_down, features_test_down), 2)\n",
    "model_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для логистической регрессии наилучший результат получен при уменьшении значений класса =0 в тренировочной выборки на 30% - $f1_{score}=0,77$. Дальнейшее уменьшение выборки итоговый результат не улучшало. Остановим свой выбор на увеличенной значениями класса =1 тренировочной выборке и перейдем к более сложным моделям."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим модель Случайный лес для решения нашей задачи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {'max_depth': hp.choice(\"max_depth\", np.arange(1, 25, dtype = int)),\n",
    "        'n_estimators' : hp.choice(\"n_estimators\", np.arange(1, 60, dtype = int))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [06:22<00:00, 38.28s/trial, best loss: -0.03655429681029367]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn = partial(hyperopt_score, \n",
    "                         x_train = features_train_up, y_train = target_train_up, \n",
    "                         type_model = RandomForestClassifier), \n",
    "                                                     space = space, algo = tpe.suggest, \n",
    "                                                     max_evals = 10, trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20, 'n_estimators': 10}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metric.loc['f1_train', 'RF_up'] = round(-trials.results[np.argmin([r['loss'] for r in trials.results])]['loss'], 2)\n",
    "\n",
    "hyper_param = {'max_depth' : trials.results[np.argmin([r['loss'] for r in trials.results])]['params']['max_depth'],\n",
    "              'n_estimators' : trials.results[np.argmin([r['loss'] for r in trials.results])]['params']['n_estimators']}\n",
    "hyper_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tree</th>\n",
       "      <th>LR</th>\n",
       "      <th>LR_up</th>\n",
       "      <th>Tree_up</th>\n",
       "      <th>LR_down</th>\n",
       "      <th>RF_up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1_train</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_test</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Tree    LR  LR_up  Tree_up  LR_down  RF_up\n",
       "f1_train  0.6   0.70  0.80   0.68     0.79     0.04 \n",
       "f1_test   0.63  0.73  0.78   0.64     0.77     0.02 "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metric.loc['f1_test', 'RF_up'] = round(test_func_model(hyper_param, RandomForestClassifier, \n",
    "                                                          features_train_up, target_train_up), 2)\n",
    "model_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель RandomForestClassifier на тестовой выборке показала наихудший результат среди рассмотренных вариантов с $f1_{score} =0,02$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {'max_depth': hp.choice(\"max_depth\", np.arange(1, 15, dtype = int)),\n",
    "        'n_estimators' : hp.choice(\"n_estimators\", np.arange(1, 60, dtype = int))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [17:04<00:00, 102.47s/trial, best loss: -0.8170730181272067]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn = partial(hyperopt_score, \n",
    "                         x_train = features_train_up, y_train = target_train_up, \n",
    "                         type_model = XGBClassifier), \n",
    "                                                     space = space, algo = tpe.suggest, \n",
    "                                                     max_evals = 10, trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 14, 'n_estimators': 49}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metric.loc['f1_train', 'XGB_up'] = round(-trials.results[np.argmin([r['loss'] for r in trials.results])]['loss'], 2)\n",
    "\n",
    "hyper_param = {'max_depth' : trials.results[np.argmin([r['loss'] for r in trials.results])]['params']['max_depth'],\n",
    "              'n_estimators' : trials.results[np.argmin([r['loss'] for r in trials.results])]['params']['n_estimators']}\n",
    "hyper_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tree</th>\n",
       "      <th>LR</th>\n",
       "      <th>LR_up</th>\n",
       "      <th>Tree_up</th>\n",
       "      <th>LR_down</th>\n",
       "      <th>RF_up</th>\n",
       "      <th>XGB_up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1_train</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_test</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Tree    LR  LR_up  Tree_up  LR_down  RF_up  XGB_up\n",
       "f1_train  0.6   0.70  0.80   0.68     0.79     0.04   0.82  \n",
       "f1_test   0.63  0.73  0.78   0.64     0.77     0.02   0.76  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metric.loc['f1_test', 'XGB_up'] = round(test_func_model(hyper_param, XGBClassifier, \n",
    "                                                              features_train_up, target_train_up), 2)\n",
    "model_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель XGBClassifier на тестовых данных показала результат метрики $f1_{score} =0,76$, также выполнив поставленное требование. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим вариант предсказаний с помощью нейронной сети. Ограничимся выборкой из 2000 текстов для ускорения процесса обработки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "adc0ded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 2000 # количество текстов из выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3464a2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = data.sample(SAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2743a3cf",
   "metadata": {},
   "source": [
    "Инициализируем модель класса DistilBERT, передав ей файл с предобученной моделью и конфигурацией, инициализируем токенизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "448161a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (transformers.DistilBertModel, \n",
    "                                                    transformers.DistilBertTokenizer, \n",
    "                                                    'distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4a232f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5355b5",
   "metadata": {},
   "source": [
    "Преобразуем тексты в векторы. В связи с особенностью модели ограничимся размером одного вектора =512, т.е. фактически обрежем все тексты, превышающие размер в 512 символов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e194ab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH_TEXT = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bbd691d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "tokenized = data_sample['text'].apply(lambda x: \n",
    "                                      tokenizer.encode(x, add_special_tokens = True, max_length = LENGTH_TEXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2fc4bce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61661    [101, 2008, 1005, 1055, 2025, 2033, 1998, 3504, 2066, 2017, 2024, 1996, 2028, 2725, 1996, 18820, 18965, 2011, 5815, 2008, 27420, 2227, 6148, 2010, 4519, 102]                      \n",
       "44925    [101, 3531, 2079, 2025, 3158, 9305, 4697, 5530, 2004, 2017, 2106, 2007, 2023, 10086, 2000, 2572, 4576, 2065, 2017, 3613, 2000, 2079, 2061, 2017, 2097, 2022, 8534, 2013, 9260, 102]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c587cbad",
   "metadata": {},
   "source": [
    "Для быстрой работы Bert заполним полученные векторы нулями до максимальной длины"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f61b20b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = np.array(list(map(lambda x: x + [0] * (LENGTH_TEXT - len(x)), np.array(tokenized))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "412cb2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 512)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5122bbc",
   "metadata": {},
   "source": [
    "Скроем для Bert нули, заполненные нами в векторах, с помощью маски"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "970f477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b1437ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "95c310cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 512)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba4325d",
   "metadata": {},
   "source": [
    "Для экономии опративной памяти ограничим размер батчей с эмбедингами, которые создает Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d0c11081",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100 # размер батча"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f1ec55c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df85885b3a24d5a8ac5c68fc269592a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // BATCH_SIZE)):\n",
    "    \n",
    "    # Перебираем батчи и переводим в формат тензоров (многомерных векторов)\n",
    "    batch = torch.LongTensor(padded[BATCH_SIZE * i : BATCH_SIZE * (i + 1)])\n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[BATCH_SIZE * i : BATCH_SIZE * (i + 1)])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        batch_embeddings = model(batch, attention_mask = attention_mask_batch)\n",
    "    \n",
    "    # для задачи классификации оставляем выход BERT'а для токена [CLS], остальное отбрасываем\n",
    "    embeddings.append(batch_embeddings[0][:,0,:].numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a4acd852",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b3f7f7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03535952, -0.07927292, -0.01615617, ..., -0.24551621,\n",
       "         0.4235055 ,  0.24310385],\n",
       "       [ 0.05332525,  0.16472387, -0.25779337, ..., -0.05152125,\n",
       "         0.45004097,  0.33295387],\n",
       "       [ 0.1318903 , -0.05567373, -0.292391  , ..., -0.0716961 ,\n",
       "         0.49964628,  0.42272303],\n",
       "       ...,\n",
       "       [ 0.10383351, -0.20728599, -0.14604987, ..., -0.23507291,\n",
       "         0.2925673 ,  0.20484142],\n",
       "       [-0.19480382, -0.07343734, -0.00076875, ..., -0.05508371,\n",
       "         0.19796346,  0.28604695],\n",
       "       [ 0.17202017,  0.09881824, -0.38155013, ..., -0.07690867,\n",
       "         0.46900654,  0.37409693]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = np.concatenate((features, \n",
    "                           data.loc[data_sample.index][['ex_point']].values, \n",
    "                           data.loc[data_sample.index][['caps']].values), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_bert, features_test_bert, target_train_bert, target_test_bert = train_test_split(features_all, \n",
    "                                                                            data_sample['toxic'], \n",
    "                                                                            test_size = 0.3, \n",
    "                                                                            random_state = 12345,\n",
    "                                                                            stratify = data_sample['toxic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state = 12345, solver = 'liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metric.loc['f1_train', 'LR_bert'] = round(cross_val_score(model, features_train_bert, target_train_bert, \n",
    "                                                         scoring = 'f1', cv = 3).mean(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим модель на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tree</th>\n",
       "      <th>LR</th>\n",
       "      <th>LR_up</th>\n",
       "      <th>Tree_up</th>\n",
       "      <th>LR_down</th>\n",
       "      <th>RF_up</th>\n",
       "      <th>XGB_up</th>\n",
       "      <th>LR_bert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1_train</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_test</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Tree    LR  LR_up  Tree_up  LR_down  RF_up  XGB_up  LR_bert\n",
       "f1_train  0.6   0.70  0.80   0.68     0.79     0.04   0.82    0.65   \n",
       "f1_test   0.63  0.73  0.78   0.64     0.77     0.02   0.76    0.71   "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_param = {'solver' : 'liblinear'}\n",
    "model_metric.loc['f1_test', 'LR_bert'] = round(test_func_model(hyper_param, LogisticRegression, \n",
    "                                                               features_train_bert, target_train_bert, \n",
    "                                                               features_test_bert, target_test_bert), 2)\n",
    "model_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель логистической регрессии с использованием нейронных сетей показала себя чуть хуже $f1_{score}=0,71$ yна тестовых данных чем она же на предсказании с помощью TF-IDF, где $f1_{score}=0,73$. Попробуем сбалансировать выборку, увеличив количество строк со значениям класса =1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b0ee4220",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_zero_bert = features_train_bert[target_train_bert == 0]\n",
    "features_train_one_bert = features_train_bert[target_train_bert == 1]\n",
    "\n",
    "target_train_zero_bert = target_train_bert[target_train_bert == 0]\n",
    "target_train_one_bert = target_train_bert[target_train_bert == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c540a8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_bert_up = np.concatenate([features_train_zero_bert] + [features_train_one_bert] * 2)\n",
    "target_train_bert_up = np.concatenate([target_train_zero_bert] + [target_train_one_bert] * 2)\n",
    "\n",
    "features_train_bert_up = shuffle(features_train_bert_up, random_state = 12345)\n",
    "target_train_bert_up = shuffle(target_train_bert_up, random_state = 12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metric.loc['f1_train', 'LR_bert_up'] = round(cross_val_score(model, features_train_bert_up, target_train_bert_up, \n",
    "                                                         scoring = 'f1', cv = 3).mean(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tree</th>\n",
       "      <th>LR</th>\n",
       "      <th>LR_up</th>\n",
       "      <th>Tree_up</th>\n",
       "      <th>LR_down</th>\n",
       "      <th>RF_up</th>\n",
       "      <th>XGB_up</th>\n",
       "      <th>LR_bert</th>\n",
       "      <th>LR_bert_up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1_train</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_test</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Tree    LR  LR_up  Tree_up  LR_down  RF_up  XGB_up  LR_bert  \\\n",
       "f1_train  0.6   0.70  0.80   0.68     0.79     0.04   0.82    0.65      \n",
       "f1_test   0.63  0.73  0.78   0.64     0.77     0.02   0.76    0.71      \n",
       "\n",
       "          LR_bert_up  \n",
       "f1_train  0.80        \n",
       "f1_test   0.72        "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_param = {'solver' : 'liblinear'}\n",
    "model_metric.loc['f1_test', 'LR_bert_up'] = round(test_func_model(hyper_param, LogisticRegression, \n",
    "                                                               features_train_bert_up, target_train_bert_up, \n",
    "                                                               features_test_bert, target_test_bert), 2)\n",
    "model_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увеличение значений класса =1 в тренировочной выборке совсем незначтельно повлияло на резуьтат предсказания $f1_{score}=0,72$. Значение метрики улучшилось все на 0,01. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f7ab27",
   "metadata": {},
   "source": [
    "### LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем модель LGBMClassifier без увеличения выборки значениями класса =1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "653f9f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {'max_depth': hp.choice(\"max_depth\", np.arange(1, 15, dtype = int)),\n",
    "        'n_estimators' : hp.choice(\"n_estimators\", np.arange(1, 60, dtype = int)),\n",
    "        'num_leaves' : hp.choice(\"num_leaves\", np.arange(5, 31, dtype = int))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9f960cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:33<00:00,  3.37s/trial, best loss: -0.555531867643793]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn = partial(hyperopt_score, \n",
    "                         x_train = features_train_bert, y_train = target_train_bert, \n",
    "                         type_model = lgb.LGBMClassifier), \n",
    "                                                     space = space, algo = tpe.suggest, \n",
    "                                                     max_evals = 10, trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fc37e17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 11, 'n_estimators': 56, 'num_leaves': 10}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metric.loc['f1_train', 'LGBM_bert'] = round(-trials.results[np.argmin([r['loss'] for r in trials.results])]['loss'], 2)\n",
    "hyper_param = {'max_depth' : trials.results[np.argmin([r['loss'] for r in trials.results])]['params']['max_depth'],\n",
    "              'n_estimators' : trials.results[np.argmin([r['loss'] for r in trials.results])]['params']['n_estimators'],\n",
    "              'num_leaves' : trials.results[np.argmin([r['loss'] for r in trials.results])]['params']['num_leaves']}\n",
    "hyper_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9518b146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tree</th>\n",
       "      <th>LR</th>\n",
       "      <th>LR_up</th>\n",
       "      <th>Tree_up</th>\n",
       "      <th>LR_down</th>\n",
       "      <th>RF_up</th>\n",
       "      <th>XGB_up</th>\n",
       "      <th>LR_bert</th>\n",
       "      <th>LR_bert_up</th>\n",
       "      <th>LGBM_bert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1_train</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_test</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Tree    LR  LR_up  Tree_up  LR_down  RF_up  XGB_up  LR_bert  \\\n",
       "f1_train  0.6   0.70  0.80   0.68     0.79     0.04   0.82    0.65      \n",
       "f1_test   0.63  0.73  0.78   0.64     0.77     0.02   0.76    0.71      \n",
       "\n",
       "          LR_bert_up  LGBM_bert  \n",
       "f1_train  0.80        0.56       \n",
       "f1_test   0.72        0.59       "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metric.loc['f1_test', 'LGBM_bert'] = round(test_func_model(hyper_param, lgb.LGBMClassifier, \n",
    "                                                      features_train_bert, target_train_bert,  \n",
    "                                                      features_test_bert, target_test_bert), 2)\n",
    "model_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель LGBMClassifier с $f1_{score}=0,59$ на тестовой выборке показала наихудший результат из рассмотренных вариантов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кривая ошибок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим кривую ошибок для наилучшей модели LoggisticRegression, чтобы сравнить со случайной моделью и рассчитаем метрику AUC-ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.7807881773399015\n",
      "Recall: 0.7163105998356615\n",
      "Accuracy: 0.8580216535433071\n",
      "AUC-ROC 0.9731432537815174\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state = 12345, solver = 'liblinear')\n",
    "model.fit(features_train_up, target_train_up)\n",
    "\n",
    "probabilities_test = model.predict_proba(features_test)\n",
    "probabilities_test_ones = probabilities_test[:, 1]\n",
    "predicted_test = model.predict(features_test)\n",
    "fpr, tpr, threshold = roc_curve(target_test, probabilities_test_ones)\n",
    "\n",
    "print('f1_score:', f1_score(target_test, predicted_test))\n",
    "print('Recall:', recall_score(target_test, predicted_test))\n",
    "print('Accuracy:', precision_score(target_test, predicted_test))\n",
    "print('AUC-ROC', roc_auc_score(target_test, probabilities_test_ones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title(\"ROC-кривая\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках этапа в результате перебора моделей была выбрана модель, показавшая на тестовой выборке наилучшее значение метрики $f1_{score}=0,78$. Этой моделью оказалась модель логистической регрессии. Модель показала наилучший результат при увеличении в тренировочной выборке количества строк с классом =1, что позволяет уменьшить влияние дисбаланса классов. \n",
    "\n",
    "Судя по значению метрики $Accuracy=0,86$ модель достаточно точно определяет токсичные комментарии. Однако, если взяглянуть на значение метрики $Recall=0,71$, можно понять, что модель отлавливает не все токсичные комментарии, только 71%. Для улучшения метрик можно более скурпулезно подойти к подбору гиперпараметров рассмотренных моделей, что, конечно же, увеличит время как самого исследования так и время обучения самих моделей. \n",
    "\n",
    "Кроме того, при желании по графику ROC-кривой можно подобрать такое значение порога классификации (соотношение парметров TPR и FPR), которое удовлетворит требования заказчика. К примеру, пожертвовать точностью определения токсичных комментариев (увеличится FPR), но затоповысить полноту определения истиннополжительных значений (TPR)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках данного исследования был проведен анализ текстов комментариев и разработаны модели для предсказания по тексту комментария его токсчичности или нетокисчности.\n",
    "\n",
    "На первом этапе проекта были сделаны предположения о влиянии соотношения количества слов с прописными буквами и общего количества символов в текстах, а также количества восклицательных знаков в текстах к общему количеству символов в текстах. Предположения были подтверждены на основе графиков распределения характеристик. Характеристики были добавлены в общую таблицу признаков. Также на первом этапе была проведена обработка и лемматизация текстов, создана таблица с оцнкой важности слов TF-IDF.\n",
    "\n",
    "На втором этапе были построены несколько моделей, где в качестве признаков использовалась матрица с оценками важности слов TF-IDF c двумя допонительными признаками, выявленными на первом этапе. Для уменьшения влияния дисбаланса классов было рассмотрено несколько ваиантов решения: увеличение веса класса \"1\", увеличение в тренировочной выборке количества строк с классом \"1\", уменьшение количества строк с классом \"0\". Налучший результат $f1_{score}=0,78$ дала модель логистической регрессии с увеличенной за счет строк с классом \"1\" тренировочной выборкой. Данная модель обеспечила требование заказчика на значение метрики  $f1_{score}>0,75$.\n",
    "\n",
    "Далее были разработаны модели предсказания с использованием нейронной сети DestillBert. Предварительно тексты комментариев были преобразованы нейронной сетью в эмбеддинги, которые в дальнейшем стали матрицей признаков для разрабатываемых моделей. Были рассмотрены модели логистической регрессии и LGBMClassifier. К сожалению, данные модели показали результат хуже чем модели на базе матрицы TF-IDF. Наилучший результат показала модель логистической регресии с $f1_{score}=0,72$, что не удовлетворяет поставленной задаче. Для улучшения результата моделей с использованием нейронных сетей необходимо лучше подбирать гиперпараметры моделей и сами модели классификации. Кроме того, можно рассматривать другие модели перевода слов в векторное сосотояние, различные варианты словарей, на которых обучались модели, варианты лемматизации текстов."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 3,
    "start_time": "2022-05-29T10:16:06.043Z"
   },
   {
    "duration": 5331,
    "start_time": "2022-05-29T10:16:06.049Z"
   },
   {
    "duration": 8670,
    "start_time": "2022-05-29T10:16:11.383Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-29T10:16:20.056Z"
   },
   {
    "duration": 912,
    "start_time": "2022-05-29T10:16:20.062Z"
   },
   {
    "duration": 21,
    "start_time": "2022-05-29T10:16:20.976Z"
   },
   {
    "duration": 39,
    "start_time": "2022-05-29T10:16:20.999Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-29T10:16:21.041Z"
   },
   {
    "duration": 38,
    "start_time": "2022-05-29T10:16:21.055Z"
   },
   {
    "duration": 116,
    "start_time": "2022-05-29T10:16:21.097Z"
   },
   {
    "duration": 351,
    "start_time": "2022-05-29T10:16:21.215Z"
   },
   {
    "duration": 1568,
    "start_time": "2022-05-29T10:16:21.569Z"
   },
   {
    "duration": 344,
    "start_time": "2022-05-29T10:16:23.139Z"
   },
   {
    "duration": 283,
    "start_time": "2022-05-29T10:16:23.486Z"
   },
   {
    "duration": 302,
    "start_time": "2022-05-29T10:16:23.771Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-29T10:39:58.625Z"
   },
   {
    "duration": 17,
    "start_time": "2022-05-29T10:39:58.633Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-29T10:39:58.652Z"
   },
   {
    "duration": 1092,
    "start_time": "2022-05-29T10:39:58.668Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-29T10:39:59.762Z"
   },
   {
    "duration": 44,
    "start_time": "2022-05-29T10:39:59.776Z"
   },
   {
    "duration": 20,
    "start_time": "2022-05-29T10:39:59.822Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-29T10:39:59.844Z"
   },
   {
    "duration": 114,
    "start_time": "2022-05-29T10:39:59.856Z"
   },
   {
    "duration": 440,
    "start_time": "2022-05-29T10:39:59.973Z"
   },
   {
    "duration": 2245,
    "start_time": "2022-05-29T10:40:00.415Z"
   },
   {
    "duration": 417,
    "start_time": "2022-05-29T10:40:02.662Z"
   },
   {
    "duration": 397,
    "start_time": "2022-05-29T10:40:03.082Z"
   },
   {
    "duration": 417,
    "start_time": "2022-05-29T10:40:03.481Z"
   },
   {
    "duration": 5861,
    "start_time": "2022-05-29T10:40:03.901Z"
   },
   {
    "duration": 2,
    "start_time": "2022-05-29T10:40:09.765Z"
   },
   {
    "duration": 15,
    "start_time": "2022-05-29T10:40:09.769Z"
   },
   {
    "duration": 71205,
    "start_time": "2022-05-29T10:40:09.789Z"
   },
   {
    "duration": 71,
    "start_time": "2022-05-29T10:41:34.127Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-29T10:42:55.723Z"
   },
   {
    "duration": 52020,
    "start_time": "2022-05-29T10:42:58.922Z"
   },
   {
    "duration": 14,
    "start_time": "2022-05-29T10:44:15.852Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-29T10:55:27.883Z"
   },
   {
    "duration": 100,
    "start_time": "2022-05-29T11:20:18.845Z"
   },
   {
    "duration": 7575,
    "start_time": "2022-05-29T11:22:28.520Z"
   },
   {
    "duration": 357,
    "start_time": "2022-05-29T11:23:24.841Z"
   },
   {
    "duration": 257,
    "start_time": "2022-05-29T11:24:14.601Z"
   },
   {
    "duration": 8621,
    "start_time": "2022-05-29T11:25:05.912Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-29T11:25:31.634Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-29T11:25:47.010Z"
   },
   {
    "duration": 26,
    "start_time": "2022-05-29T11:31:15.353Z"
   },
   {
    "duration": 22,
    "start_time": "2022-05-29T11:31:25.488Z"
   },
   {
    "duration": 21,
    "start_time": "2022-05-29T11:31:29.351Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-29T11:31:32.931Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-29T11:31:39.807Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-29T11:33:27.655Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-29T11:34:16.096Z"
   },
   {
    "duration": 35,
    "start_time": "2022-05-29T11:40:11.519Z"
   },
   {
    "duration": 7057,
    "start_time": "2022-05-29T11:42:22.902Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-29T11:43:39.385Z"
   },
   {
    "duration": 32,
    "start_time": "2022-05-29T11:46:58.530Z"
   },
   {
    "duration": 24,
    "start_time": "2022-05-29T11:47:12.952Z"
   },
   {
    "duration": 30,
    "start_time": "2022-05-29T11:47:32.911Z"
   },
   {
    "duration": 26,
    "start_time": "2022-05-29T11:47:45.612Z"
   },
   {
    "duration": 99,
    "start_time": "2022-05-29T11:48:30.087Z"
   },
   {
    "duration": 6987,
    "start_time": "2022-05-29T11:48:41.927Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-29T11:49:10.118Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-29T11:49:11.551Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-29T11:49:19.831Z"
   },
   {
    "duration": 7653,
    "start_time": "2022-05-29T11:49:24.535Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-29T13:33:56.826Z"
   },
   {
    "duration": 15698,
    "start_time": "2022-05-29T13:33:56.834Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-29T13:34:12.535Z"
   },
   {
    "duration": 3259,
    "start_time": "2022-05-29T13:34:12.543Z"
   },
   {
    "duration": 21,
    "start_time": "2022-05-29T13:34:15.805Z"
   },
   {
    "duration": 32,
    "start_time": "2022-05-29T13:34:15.827Z"
   },
   {
    "duration": 28,
    "start_time": "2022-05-29T13:34:15.861Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-29T13:34:15.891Z"
   },
   {
    "duration": 85,
    "start_time": "2022-05-29T13:34:15.902Z"
   },
   {
    "duration": 323,
    "start_time": "2022-05-29T13:34:15.989Z"
   },
   {
    "duration": 1537,
    "start_time": "2022-05-29T13:34:16.315Z"
   },
   {
    "duration": 323,
    "start_time": "2022-05-29T13:34:17.854Z"
   },
   {
    "duration": 241,
    "start_time": "2022-05-29T13:34:18.179Z"
   },
   {
    "duration": 279,
    "start_time": "2022-05-29T13:34:18.422Z"
   },
   {
    "duration": 3893,
    "start_time": "2022-05-29T13:34:18.703Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-29T13:34:22.598Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-29T13:34:22.603Z"
   },
   {
    "duration": 46423,
    "start_time": "2022-05-29T13:34:22.610Z"
   },
   {
    "duration": 37,
    "start_time": "2022-05-29T13:35:09.035Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-29T13:35:09.074Z"
   },
   {
    "duration": 69,
    "start_time": "2022-05-29T13:35:09.083Z"
   },
   {
    "duration": 6922,
    "start_time": "2022-05-29T13:35:09.153Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-29T13:35:16.076Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-29T13:35:16.082Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-29T13:35:16.092Z"
   },
   {
    "duration": 6943,
    "start_time": "2022-05-29T13:35:16.098Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-29T13:37:26.709Z"
   },
   {
    "duration": 2,
    "start_time": "2022-05-29T13:39:27.314Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-29T13:39:27.324Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-29T13:39:27.332Z"
   },
   {
    "duration": 710,
    "start_time": "2022-05-29T13:39:27.339Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-29T13:39:28.050Z"
   },
   {
    "duration": 33,
    "start_time": "2022-05-29T13:39:28.067Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-29T13:39:28.103Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-29T13:39:28.109Z"
   },
   {
    "duration": 93,
    "start_time": "2022-05-29T13:39:28.123Z"
   },
   {
    "duration": 294,
    "start_time": "2022-05-29T13:39:28.218Z"
   },
   {
    "duration": 1414,
    "start_time": "2022-05-29T13:39:28.514Z"
   },
   {
    "duration": 294,
    "start_time": "2022-05-29T13:39:29.930Z"
   },
   {
    "duration": 260,
    "start_time": "2022-05-29T13:39:30.227Z"
   },
   {
    "duration": 294,
    "start_time": "2022-05-29T13:39:30.489Z"
   },
   {
    "duration": 3825,
    "start_time": "2022-05-29T13:39:30.785Z"
   },
   {
    "duration": 2,
    "start_time": "2022-05-29T13:39:34.612Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-29T13:39:34.616Z"
   },
   {
    "duration": 47016,
    "start_time": "2022-05-29T13:39:34.626Z"
   },
   {
    "duration": 36,
    "start_time": "2022-05-29T13:40:21.644Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-29T13:40:21.681Z"
   },
   {
    "duration": 95,
    "start_time": "2022-05-29T13:40:21.692Z"
   },
   {
    "duration": 6961,
    "start_time": "2022-05-29T13:40:21.788Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-29T13:40:28.751Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-29T13:40:28.758Z"
   },
   {
    "duration": 38,
    "start_time": "2022-05-29T13:40:28.769Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-29T13:41:05.266Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-29T16:42:57.008Z"
   },
   {
    "duration": 12927,
    "start_time": "2022-05-29T16:42:57.013Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-29T16:43:09.942Z"
   },
   {
    "duration": 2096,
    "start_time": "2022-05-29T16:43:09.949Z"
   },
   {
    "duration": 15,
    "start_time": "2022-05-29T16:43:12.047Z"
   },
   {
    "duration": 28,
    "start_time": "2022-05-29T16:43:12.064Z"
   },
   {
    "duration": 15,
    "start_time": "2022-05-29T16:43:12.093Z"
   },
   {
    "duration": 16,
    "start_time": "2022-05-29T16:43:12.110Z"
   },
   {
    "duration": 91,
    "start_time": "2022-05-29T16:43:12.128Z"
   },
   {
    "duration": 305,
    "start_time": "2022-05-29T16:43:12.220Z"
   },
   {
    "duration": 1362,
    "start_time": "2022-05-29T16:43:12.526Z"
   },
   {
    "duration": 296,
    "start_time": "2022-05-29T16:43:13.889Z"
   },
   {
    "duration": 245,
    "start_time": "2022-05-29T16:43:14.187Z"
   },
   {
    "duration": 276,
    "start_time": "2022-05-29T16:43:14.434Z"
   },
   {
    "duration": 3638,
    "start_time": "2022-05-29T16:43:14.711Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-29T16:43:18.351Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-29T16:43:18.356Z"
   },
   {
    "duration": 45481,
    "start_time": "2022-05-29T16:43:18.364Z"
   },
   {
    "duration": 38,
    "start_time": "2022-05-29T16:44:03.847Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-29T16:44:03.887Z"
   },
   {
    "duration": 84,
    "start_time": "2022-05-29T16:44:03.897Z"
   },
   {
    "duration": 6476,
    "start_time": "2022-05-29T16:44:03.982Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-29T16:44:10.460Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-29T16:44:10.465Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-29T16:44:10.475Z"
   },
   {
    "duration": 6675,
    "start_time": "2022-05-29T16:44:10.481Z"
   },
   {
    "duration": 320,
    "start_time": "2022-05-29T16:44:46.926Z"
   },
   {
    "duration": 4242,
    "start_time": "2022-05-29T16:44:57.290Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-29T16:46:25.275Z"
   },
   {
    "duration": 19,
    "start_time": "2022-05-29T16:46:38.593Z"
   },
   {
    "duration": 22,
    "start_time": "2022-05-29T16:46:57.805Z"
   },
   {
    "duration": 59,
    "start_time": "2022-05-29T16:47:04.682Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-29T16:48:28.601Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-29T16:48:37.975Z"
   },
   {
    "duration": 21,
    "start_time": "2022-05-29T16:49:37.854Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-29T16:50:05.616Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-29T16:50:44.657Z"
   },
   {
    "duration": 60,
    "start_time": "2022-05-29T16:51:07.788Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-29T16:51:58.672Z"
   },
   {
    "duration": 13016,
    "start_time": "2022-05-29T16:51:58.678Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-29T16:52:11.697Z"
   },
   {
    "duration": 2115,
    "start_time": "2022-05-29T16:52:11.705Z"
   },
   {
    "duration": 16,
    "start_time": "2022-05-29T16:52:13.822Z"
   },
   {
    "duration": 28,
    "start_time": "2022-05-29T16:52:13.840Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-29T16:52:13.869Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-29T16:52:13.876Z"
   },
   {
    "duration": 94,
    "start_time": "2022-05-29T16:52:13.887Z"
   },
   {
    "duration": 313,
    "start_time": "2022-05-29T16:52:13.982Z"
   },
   {
    "duration": 1368,
    "start_time": "2022-05-29T16:52:14.297Z"
   },
   {
    "duration": 283,
    "start_time": "2022-05-29T16:52:15.666Z"
   },
   {
    "duration": 257,
    "start_time": "2022-05-29T16:52:15.952Z"
   },
   {
    "duration": 303,
    "start_time": "2022-05-29T16:52:16.211Z"
   },
   {
    "duration": 3650,
    "start_time": "2022-05-29T16:52:16.515Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-29T16:52:20.168Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-29T16:52:20.173Z"
   },
   {
    "duration": 44678,
    "start_time": "2022-05-29T16:52:20.185Z"
   },
   {
    "duration": 36,
    "start_time": "2022-05-29T16:53:04.865Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-29T16:53:04.903Z"
   },
   {
    "duration": 89,
    "start_time": "2022-05-29T16:53:04.914Z"
   },
   {
    "duration": 6317,
    "start_time": "2022-05-29T16:53:05.005Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-29T16:53:11.323Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-29T16:53:11.329Z"
   },
   {
    "duration": 16,
    "start_time": "2022-05-29T16:53:11.336Z"
   },
   {
    "duration": 6551,
    "start_time": "2022-05-29T16:53:11.353Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-29T16:53:17.906Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-29T17:37:22.216Z"
   },
   {
    "duration": 28,
    "start_time": "2022-05-29T17:38:51.442Z"
   },
   {
    "duration": 75,
    "start_time": "2022-05-29T17:39:22.762Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-29T17:39:57.171Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-29T17:40:06.979Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-29T17:40:23.979Z"
   },
   {
    "duration": 420,
    "start_time": "2022-05-29T17:40:55.160Z"
   },
   {
    "duration": 85,
    "start_time": "2022-05-29T17:41:11.870Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-29T17:41:16.673Z"
   },
   {
    "duration": 21,
    "start_time": "2022-05-29T17:41:41.142Z"
   },
   {
    "duration": 451,
    "start_time": "2022-05-29T17:42:21.283Z"
   },
   {
    "duration": 68,
    "start_time": "2022-05-29T17:42:37.851Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-29T17:42:42.233Z"
   },
   {
    "duration": 69,
    "start_time": "2022-05-29T17:43:35.829Z"
   },
   {
    "duration": 54,
    "start_time": "2022-05-29T17:44:14.809Z"
   },
   {
    "duration": 36,
    "start_time": "2022-05-29T17:44:21.702Z"
   },
   {
    "duration": 80,
    "start_time": "2022-05-29T17:54:14.992Z"
   },
   {
    "duration": 6901,
    "start_time": "2022-05-29T17:54:18.765Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-29T17:54:39.524Z"
   },
   {
    "duration": 7215,
    "start_time": "2022-05-29T17:54:41.342Z"
   },
   {
    "duration": 122,
    "start_time": "2022-05-29T17:57:23.824Z"
   },
   {
    "duration": 2,
    "start_time": "2022-05-29T17:58:01.346Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-29T17:58:37.249Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-29T17:59:19.947Z"
   },
   {
    "duration": 56,
    "start_time": "2022-05-29T18:00:47.452Z"
   },
   {
    "duration": 6880,
    "start_time": "2022-05-29T18:00:55.346Z"
   },
   {
    "duration": 29,
    "start_time": "2022-05-29T18:04:14.792Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-29T18:05:14.397Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-29T18:05:18.982Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-29T18:05:35.846Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-29T18:06:17.257Z"
   },
   {
    "duration": 147,
    "start_time": "2022-05-29T18:06:25.147Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-29T18:06:34.043Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-29T18:06:47.265Z"
   },
   {
    "duration": 262,
    "start_time": "2022-05-29T18:08:32.451Z"
   },
   {
    "duration": 5513,
    "start_time": "2022-05-29T18:08:47.400Z"
   },
   {
    "duration": 131,
    "start_time": "2022-05-29T18:09:06.882Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-29T18:09:31.281Z"
   },
   {
    "duration": 2981,
    "start_time": "2022-05-30T11:47:30.298Z"
   },
   {
    "duration": 22684,
    "start_time": "2022-05-30T11:47:33.281Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-30T11:47:55.971Z"
   },
   {
    "duration": 3484,
    "start_time": "2022-05-30T11:47:55.980Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-30T11:47:59.466Z"
   },
   {
    "duration": 32,
    "start_time": "2022-05-30T11:47:59.486Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-30T11:47:59.520Z"
   },
   {
    "duration": 43,
    "start_time": "2022-05-30T11:47:59.531Z"
   },
   {
    "duration": 103,
    "start_time": "2022-05-30T11:47:59.576Z"
   },
   {
    "duration": 332,
    "start_time": "2022-05-30T11:47:59.683Z"
   },
   {
    "duration": 1800,
    "start_time": "2022-05-30T11:48:00.017Z"
   },
   {
    "duration": 359,
    "start_time": "2022-05-30T11:48:01.820Z"
   },
   {
    "duration": 329,
    "start_time": "2022-05-30T11:48:02.182Z"
   },
   {
    "duration": 322,
    "start_time": "2022-05-30T11:48:02.512Z"
   },
   {
    "duration": 4568,
    "start_time": "2022-05-30T11:48:02.837Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-30T11:48:07.407Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-30T11:48:07.412Z"
   },
   {
    "duration": 53561,
    "start_time": "2022-05-30T11:48:07.436Z"
   },
   {
    "duration": 58,
    "start_time": "2022-05-30T11:49:00.999Z"
   },
   {
    "duration": 36,
    "start_time": "2022-05-30T11:49:01.058Z"
   },
   {
    "duration": 91,
    "start_time": "2022-05-30T11:49:01.095Z"
   },
   {
    "duration": 7777,
    "start_time": "2022-05-30T11:49:01.188Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-30T11:49:08.967Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-30T11:49:08.974Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-30T11:49:08.983Z"
   },
   {
    "duration": 2429,
    "start_time": "2022-05-30T12:08:09.614Z"
   },
   {
    "duration": 16242,
    "start_time": "2022-05-30T12:08:12.046Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-30T12:08:28.290Z"
   },
   {
    "duration": 2526,
    "start_time": "2022-05-30T12:08:28.297Z"
   },
   {
    "duration": 23,
    "start_time": "2022-05-30T12:08:30.825Z"
   },
   {
    "duration": 33,
    "start_time": "2022-05-30T12:08:30.849Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-30T12:08:30.884Z"
   },
   {
    "duration": 38,
    "start_time": "2022-05-30T12:08:30.899Z"
   },
   {
    "duration": 94,
    "start_time": "2022-05-30T12:08:30.945Z"
   },
   {
    "duration": 316,
    "start_time": "2022-05-30T12:08:31.042Z"
   },
   {
    "duration": 1659,
    "start_time": "2022-05-30T12:08:31.360Z"
   },
   {
    "duration": 309,
    "start_time": "2022-05-30T12:08:33.021Z"
   },
   {
    "duration": 290,
    "start_time": "2022-05-30T12:08:33.332Z"
   },
   {
    "duration": 348,
    "start_time": "2022-05-30T12:08:33.624Z"
   },
   {
    "duration": 4278,
    "start_time": "2022-05-30T12:08:33.974Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-30T12:08:38.255Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-30T12:08:38.260Z"
   },
   {
    "duration": 50214,
    "start_time": "2022-05-30T12:08:38.271Z"
   },
   {
    "duration": 50,
    "start_time": "2022-05-30T12:09:28.487Z"
   },
   {
    "duration": 14,
    "start_time": "2022-05-30T12:09:28.540Z"
   },
   {
    "duration": 85,
    "start_time": "2022-05-30T12:09:28.556Z"
   },
   {
    "duration": 7300,
    "start_time": "2022-05-30T12:09:28.643Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-30T12:09:35.945Z"
   },
   {
    "duration": 17,
    "start_time": "2022-05-30T12:09:35.951Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-30T12:09:35.970Z"
   },
   {
    "duration": 60,
    "start_time": "2022-05-30T12:11:06.741Z"
   },
   {
    "duration": 2456,
    "start_time": "2022-05-30T12:11:11.496Z"
   },
   {
    "duration": 14426,
    "start_time": "2022-05-30T12:11:13.955Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-30T12:11:28.383Z"
   },
   {
    "duration": 2572,
    "start_time": "2022-05-30T12:11:28.391Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-30T12:11:30.964Z"
   },
   {
    "duration": 63,
    "start_time": "2022-05-30T12:11:30.983Z"
   },
   {
    "duration": 16,
    "start_time": "2022-05-30T12:11:31.048Z"
   },
   {
    "duration": 23,
    "start_time": "2022-05-30T12:11:31.066Z"
   },
   {
    "duration": 92,
    "start_time": "2022-05-30T12:11:31.091Z"
   },
   {
    "duration": 312,
    "start_time": "2022-05-30T12:11:31.186Z"
   },
   {
    "duration": 1589,
    "start_time": "2022-05-30T12:11:31.499Z"
   },
   {
    "duration": 302,
    "start_time": "2022-05-30T12:11:33.090Z"
   },
   {
    "duration": 279,
    "start_time": "2022-05-30T12:11:33.394Z"
   },
   {
    "duration": 311,
    "start_time": "2022-05-30T12:11:33.675Z"
   },
   {
    "duration": 4050,
    "start_time": "2022-05-30T12:11:33.988Z"
   },
   {
    "duration": 2,
    "start_time": "2022-05-30T12:11:38.041Z"
   },
   {
    "duration": 16,
    "start_time": "2022-05-30T12:11:38.046Z"
   },
   {
    "duration": 49989,
    "start_time": "2022-05-30T12:11:38.064Z"
   },
   {
    "duration": 42,
    "start_time": "2022-05-30T12:12:28.054Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-30T12:12:28.098Z"
   },
   {
    "duration": 69,
    "start_time": "2022-05-30T12:12:28.128Z"
   },
   {
    "duration": 7162,
    "start_time": "2022-05-30T12:12:28.199Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-30T12:12:35.363Z"
   },
   {
    "duration": 19,
    "start_time": "2022-05-30T12:12:35.370Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-30T12:12:35.390Z"
   },
   {
    "duration": 7642,
    "start_time": "2022-05-30T12:14:11.394Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-30T12:14:23.468Z"
   },
   {
    "duration": 56,
    "start_time": "2022-05-30T12:17:28.085Z"
   },
   {
    "duration": 2,
    "start_time": "2022-05-30T12:17:37.768Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-30T12:17:42.666Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-30T12:18:01.922Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-30T12:18:04.175Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-30T12:18:21.523Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-30T12:18:32.634Z"
   },
   {
    "duration": 6811,
    "start_time": "2022-05-30T12:44:43.362Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-30T12:45:15.594Z"
   },
   {
    "duration": 64,
    "start_time": "2022-05-30T12:46:02.279Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-30T12:46:12.734Z"
   },
   {
    "duration": 2201,
    "start_time": "2022-05-30T12:46:25.853Z"
   },
   {
    "duration": 15484,
    "start_time": "2022-05-30T12:46:28.057Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-30T12:46:43.544Z"
   },
   {
    "duration": 2556,
    "start_time": "2022-05-30T12:46:43.551Z"
   },
   {
    "duration": 16,
    "start_time": "2022-05-30T12:46:46.109Z"
   },
   {
    "duration": 44,
    "start_time": "2022-05-30T12:46:46.128Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-30T12:46:46.174Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-30T12:46:46.182Z"
   },
   {
    "duration": 109,
    "start_time": "2022-05-30T12:46:46.194Z"
   },
   {
    "duration": 376,
    "start_time": "2022-05-30T12:46:46.307Z"
   },
   {
    "duration": 1499,
    "start_time": "2022-05-30T12:46:46.685Z"
   },
   {
    "duration": 279,
    "start_time": "2022-05-30T12:46:48.186Z"
   },
   {
    "duration": 249,
    "start_time": "2022-05-30T12:46:48.466Z"
   },
   {
    "duration": 267,
    "start_time": "2022-05-30T12:46:48.717Z"
   },
   {
    "duration": 3927,
    "start_time": "2022-05-30T12:46:48.985Z"
   },
   {
    "duration": 2,
    "start_time": "2022-05-30T12:46:52.914Z"
   },
   {
    "duration": 25,
    "start_time": "2022-05-30T12:46:52.926Z"
   },
   {
    "duration": 45829,
    "start_time": "2022-05-30T12:46:52.953Z"
   },
   {
    "duration": 56,
    "start_time": "2022-05-30T12:47:38.783Z"
   },
   {
    "duration": 14,
    "start_time": "2022-05-30T12:47:38.842Z"
   },
   {
    "duration": 80,
    "start_time": "2022-05-30T12:47:38.858Z"
   },
   {
    "duration": 6502,
    "start_time": "2022-05-30T12:47:38.940Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-30T12:47:45.444Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-30T12:47:45.449Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-30T12:47:45.462Z"
   },
   {
    "duration": 6623,
    "start_time": "2022-05-30T12:47:56.658Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-30T12:48:14.441Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-30T12:48:23.160Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-30T12:48:49.525Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-30T12:49:13.783Z"
   },
   {
    "duration": 54,
    "start_time": "2022-05-30T12:49:16.851Z"
   },
   {
    "duration": 28,
    "start_time": "2022-05-30T12:49:18.748Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-30T12:49:21.567Z"
   },
   {
    "duration": 132,
    "start_time": "2022-05-30T12:49:27.092Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-30T12:49:35.470Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-30T12:49:38.180Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-30T12:49:46.938Z"
   },
   {
    "duration": 100070,
    "start_time": "2022-05-30T12:49:49.846Z"
   },
   {
    "duration": 5569,
    "start_time": "2022-05-30T16:06:03.015Z"
   },
   {
    "duration": 6073,
    "start_time": "2022-05-30T16:06:08.587Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-30T16:06:14.661Z"
   },
   {
    "duration": 2326,
    "start_time": "2022-05-30T16:06:14.669Z"
   },
   {
    "duration": 15,
    "start_time": "2022-05-30T16:06:16.997Z"
   },
   {
    "duration": 30,
    "start_time": "2022-05-30T16:06:17.013Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-30T16:06:17.045Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-30T16:06:17.052Z"
   },
   {
    "duration": 92,
    "start_time": "2022-05-30T16:06:17.065Z"
   },
   {
    "duration": 464,
    "start_time": "2022-05-30T16:06:17.160Z"
   },
   {
    "duration": 1365,
    "start_time": "2022-05-30T16:06:17.626Z"
   },
   {
    "duration": 264,
    "start_time": "2022-05-30T16:06:18.993Z"
   },
   {
    "duration": 271,
    "start_time": "2022-05-30T16:06:19.259Z"
   },
   {
    "duration": 259,
    "start_time": "2022-05-30T16:06:19.531Z"
   },
   {
    "duration": 3584,
    "start_time": "2022-05-30T16:06:19.792Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-30T16:06:23.379Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-30T16:06:23.383Z"
   },
   {
    "duration": 41163,
    "start_time": "2022-05-30T16:06:23.392Z"
   },
   {
    "duration": 43,
    "start_time": "2022-05-30T16:07:04.556Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-30T16:07:04.601Z"
   },
   {
    "duration": 79,
    "start_time": "2022-05-30T16:07:04.610Z"
   },
   {
    "duration": 2,
    "start_time": "2022-05-30T16:07:04.691Z"
   },
   {
    "duration": 47,
    "start_time": "2022-05-30T16:07:04.695Z"
   },
   {
    "duration": 20,
    "start_time": "2022-05-30T16:07:04.744Z"
   },
   {
    "duration": 340,
    "start_time": "2022-05-30T16:07:04.766Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-30T16:07:05.108Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-30T16:07:05.109Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-30T16:07:05.110Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-30T16:07:05.111Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-30T16:07:05.112Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-30T16:07:05.113Z"
   },
   {
    "duration": 16,
    "start_time": "2022-05-30T16:11:41.915Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-30T16:12:55.390Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-30T16:13:58.994Z"
   },
   {
    "duration": 20,
    "start_time": "2022-05-30T16:14:01.864Z"
   },
   {
    "duration": 6008,
    "start_time": "2022-05-30T16:14:21.481Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-30T16:14:29.784Z"
   },
   {
    "duration": 112,
    "start_time": "2022-05-30T16:14:34.150Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-30T16:14:41.041Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-30T16:14:43.506Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-30T16:14:45.187Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-30T16:14:47.475Z"
   },
   {
    "duration": 208243,
    "start_time": "2022-05-30T16:15:03.105Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-30T16:19:04.926Z"
   },
   {
    "duration": 7209,
    "start_time": "2022-05-30T16:19:20.986Z"
   },
   {
    "duration": 17,
    "start_time": "2022-05-30T16:22:40.386Z"
   },
   {
    "duration": 2,
    "start_time": "2022-05-30T16:22:54.402Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-30T16:23:19.562Z"
   },
   {
    "duration": 48868,
    "start_time": "2022-05-30T16:23:22.875Z"
   },
   {
    "duration": 20335,
    "start_time": "2022-05-30T16:24:20.596Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-30T16:25:25.046Z"
   },
   {
    "duration": 19977,
    "start_time": "2022-05-30T16:25:29.838Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-30T16:41:53.787Z"
   },
   {
    "duration": 6641,
    "start_time": "2022-05-30T16:43:33.518Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-30T16:44:46.676Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-30T16:45:02.304Z"
   },
   {
    "duration": 25,
    "start_time": "2022-05-30T16:45:09.636Z"
   },
   {
    "duration": 17,
    "start_time": "2022-05-30T16:45:46.097Z"
   },
   {
    "duration": 95,
    "start_time": "2022-05-30T16:45:51.274Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-30T16:45:54.705Z"
   },
   {
    "duration": 37,
    "start_time": "2022-05-30T16:48:00.324Z"
   },
   {
    "duration": 19,
    "start_time": "2022-05-30T16:48:55.943Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-30T16:49:07.001Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-30T16:50:18.842Z"
   },
   {
    "duration": 19,
    "start_time": "2022-05-30T16:51:17.694Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-30T16:51:29.485Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-30T16:52:29.983Z"
   },
   {
    "duration": 1039,
    "start_time": "2022-05-30T16:52:54.208Z"
   },
   {
    "duration": 29,
    "start_time": "2022-05-30T16:53:30.420Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-30T16:53:43.196Z"
   },
   {
    "duration": 26,
    "start_time": "2022-05-30T16:54:42.477Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-30T16:54:54.491Z"
   },
   {
    "duration": 25,
    "start_time": "2022-05-30T16:55:31.903Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-30T16:55:42.127Z"
   },
   {
    "duration": 357,
    "start_time": "2022-05-30T16:56:50.644Z"
   },
   {
    "duration": 279,
    "start_time": "2022-05-30T16:57:41.396Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-30T16:58:28.973Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-30T16:58:59.512Z"
   },
   {
    "duration": 20,
    "start_time": "2022-05-30T16:59:19.270Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-30T16:59:30.158Z"
   },
   {
    "duration": 5442,
    "start_time": "2022-05-31T01:04:27.491Z"
   },
   {
    "duration": 4241,
    "start_time": "2022-05-31T01:04:32.935Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-31T01:04:37.178Z"
   },
   {
    "duration": 2290,
    "start_time": "2022-05-31T01:04:37.185Z"
   },
   {
    "duration": 15,
    "start_time": "2022-05-31T01:04:39.477Z"
   },
   {
    "duration": 30,
    "start_time": "2022-05-31T01:04:39.494Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-31T01:04:39.525Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-31T01:04:39.532Z"
   },
   {
    "duration": 91,
    "start_time": "2022-05-31T01:04:39.545Z"
   },
   {
    "duration": 287,
    "start_time": "2022-05-31T01:04:39.639Z"
   },
   {
    "duration": 1376,
    "start_time": "2022-05-31T01:04:39.928Z"
   },
   {
    "duration": 268,
    "start_time": "2022-05-31T01:04:41.305Z"
   },
   {
    "duration": 252,
    "start_time": "2022-05-31T01:04:41.574Z"
   },
   {
    "duration": 262,
    "start_time": "2022-05-31T01:04:41.828Z"
   },
   {
    "duration": 3513,
    "start_time": "2022-05-31T01:04:42.092Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T01:04:45.607Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-31T01:04:45.615Z"
   },
   {
    "duration": 41822,
    "start_time": "2022-05-31T01:04:45.625Z"
   },
   {
    "duration": 37,
    "start_time": "2022-05-31T01:05:27.449Z"
   },
   {
    "duration": 16,
    "start_time": "2022-05-31T01:05:27.488Z"
   },
   {
    "duration": 61,
    "start_time": "2022-05-31T01:05:27.505Z"
   },
   {
    "duration": 2,
    "start_time": "2022-05-31T01:05:27.568Z"
   },
   {
    "duration": 52,
    "start_time": "2022-05-31T01:05:27.572Z"
   },
   {
    "duration": 20,
    "start_time": "2022-05-31T01:05:27.626Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T01:05:27.648Z"
   },
   {
    "duration": 6566,
    "start_time": "2022-05-31T01:05:27.653Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T01:05:34.220Z"
   },
   {
    "duration": 21,
    "start_time": "2022-05-31T01:05:34.226Z"
   },
   {
    "duration": 29,
    "start_time": "2022-05-31T01:05:34.249Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-31T01:05:34.280Z"
   },
   {
    "duration": 343,
    "start_time": "2022-05-31T01:05:34.291Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T01:05:34.635Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T01:05:34.636Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T01:05:34.637Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T01:05:34.639Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T01:05:34.639Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-31T01:10:48.120Z"
   },
   {
    "duration": 19,
    "start_time": "2022-05-31T01:18:20.156Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-31T01:23:53.554Z"
   },
   {
    "duration": 6276,
    "start_time": "2022-05-31T01:24:03.168Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-31T01:24:23.923Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T01:24:33.363Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T01:24:55.584Z"
   },
   {
    "duration": 252809,
    "start_time": "2022-05-31T01:24:58.345Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-31T01:29:14.034Z"
   },
   {
    "duration": 29,
    "start_time": "2022-05-31T01:29:22.009Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-31T01:35:11.810Z"
   },
   {
    "duration": 6164,
    "start_time": "2022-05-31T01:35:13.379Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T01:35:22.924Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T01:35:26.947Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T01:35:30.102Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-31T01:35:37.548Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T01:35:39.420Z"
   },
   {
    "duration": 256662,
    "start_time": "2022-05-31T01:35:40.935Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-31T01:40:05.364Z"
   },
   {
    "duration": 9251,
    "start_time": "2022-05-31T01:40:08.451Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T01:40:33.196Z"
   },
   {
    "duration": 56837,
    "start_time": "2022-05-31T01:40:35.489Z"
   },
   {
    "duration": 19685,
    "start_time": "2022-05-31T01:41:44.698Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-31T01:42:43.969Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T01:42:59.357Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T01:43:22.272Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-31T01:43:40.138Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-31T01:43:50.003Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-31T01:44:34.277Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T01:44:56.913Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-31T01:45:05.481Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-31T01:45:23.312Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-31T01:52:50.001Z"
   },
   {
    "duration": 15,
    "start_time": "2022-05-31T01:52:51.953Z"
   },
   {
    "duration": 19,
    "start_time": "2022-05-31T01:56:06.567Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-31T01:56:27.236Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T01:56:37.987Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-31T01:57:04.736Z"
   },
   {
    "duration": 32,
    "start_time": "2022-05-31T01:58:05.791Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T01:58:14.975Z"
   },
   {
    "duration": 6534,
    "start_time": "2022-05-31T01:58:20.582Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T02:02:22.369Z"
   },
   {
    "duration": 70452,
    "start_time": "2022-05-31T02:02:30.464Z"
   },
   {
    "duration": 22730,
    "start_time": "2022-05-31T02:03:44.759Z"
   },
   {
    "duration": 225365,
    "start_time": "2022-05-31T02:13:52.916Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-31T02:17:43.307Z"
   },
   {
    "duration": 9039,
    "start_time": "2022-05-31T02:17:46.218Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-31T02:32:05.948Z"
   },
   {
    "duration": 19,
    "start_time": "2022-05-31T02:32:08.694Z"
   },
   {
    "duration": 31,
    "start_time": "2022-05-31T02:32:53.069Z"
   },
   {
    "duration": 17,
    "start_time": "2022-05-31T02:32:58.261Z"
   },
   {
    "duration": 30,
    "start_time": "2022-05-31T02:33:47.086Z"
   },
   {
    "duration": 2454,
    "start_time": "2022-05-31T02:33:53.378Z"
   },
   {
    "duration": 17052,
    "start_time": "2022-05-31T02:35:08.283Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T02:41:56.219Z"
   },
   {
    "duration": 5944,
    "start_time": "2022-05-31T02:41:58.356Z"
   },
   {
    "duration": 2128,
    "start_time": "2022-05-31T02:42:09.242Z"
   },
   {
    "duration": 2242,
    "start_time": "2022-05-31T02:46:50.716Z"
   },
   {
    "duration": 22616,
    "start_time": "2022-05-31T02:48:09.626Z"
   },
   {
    "duration": 72023,
    "start_time": "2022-05-31T02:48:37.898Z"
   },
   {
    "duration": 22725,
    "start_time": "2022-05-31T02:50:02.281Z"
   },
   {
    "duration": 39,
    "start_time": "2022-05-31T02:57:20.245Z"
   },
   {
    "duration": 3342,
    "start_time": "2022-05-31T02:57:22.842Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T02:57:29.960Z"
   },
   {
    "duration": 15222,
    "start_time": "2022-05-31T02:57:36.385Z"
   },
   {
    "duration": 9414,
    "start_time": "2022-05-31T02:57:56.646Z"
   },
   {
    "duration": 35,
    "start_time": "2022-05-31T02:58:18.243Z"
   },
   {
    "duration": 3827,
    "start_time": "2022-05-31T02:58:20.210Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T02:58:26.515Z"
   },
   {
    "duration": 31044,
    "start_time": "2022-05-31T02:58:29.158Z"
   },
   {
    "duration": 15180,
    "start_time": "2022-05-31T02:59:03.183Z"
   },
   {
    "duration": 40,
    "start_time": "2022-05-31T03:00:21.527Z"
   },
   {
    "duration": 4269,
    "start_time": "2022-05-31T03:00:23.762Z"
   },
   {
    "duration": 2,
    "start_time": "2022-05-31T03:00:37.359Z"
   },
   {
    "duration": 36316,
    "start_time": "2022-05-31T03:00:40.493Z"
   },
   {
    "duration": 15401,
    "start_time": "2022-05-31T03:01:23.772Z"
   },
   {
    "duration": 33,
    "start_time": "2022-05-31T03:01:48.072Z"
   },
   {
    "duration": 2922,
    "start_time": "2022-05-31T03:01:49.644Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T03:01:55.048Z"
   },
   {
    "duration": 9315,
    "start_time": "2022-05-31T03:01:57.389Z"
   },
   {
    "duration": 35,
    "start_time": "2022-05-31T03:03:21.611Z"
   },
   {
    "duration": 3306,
    "start_time": "2022-05-31T03:03:22.943Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T03:03:28.944Z"
   },
   {
    "duration": 20221,
    "start_time": "2022-05-31T03:03:32.088Z"
   },
   {
    "duration": 9621,
    "start_time": "2022-05-31T03:05:47.642Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T03:12:12.530Z"
   },
   {
    "duration": 91636,
    "start_time": "2022-05-31T03:12:19.942Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-31T03:13:58.603Z"
   },
   {
    "duration": 1215,
    "start_time": "2022-05-31T03:14:02.429Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-31T03:14:22.242Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-31T03:14:24.546Z"
   },
   {
    "duration": 32,
    "start_time": "2022-05-31T03:14:27.161Z"
   },
   {
    "duration": 6656,
    "start_time": "2022-05-31T03:14:30.026Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T03:15:05.220Z"
   },
   {
    "duration": 106460,
    "start_time": "2022-05-31T03:15:07.127Z"
   },
   {
    "duration": 17192,
    "start_time": "2022-05-31T03:17:01.080Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T03:17:33.782Z"
   },
   {
    "duration": 340643,
    "start_time": "2022-05-31T03:17:36.067Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-31T03:23:33.316Z"
   },
   {
    "duration": 579,
    "start_time": "2022-05-31T03:23:42.297Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-31T03:24:25.149Z"
   },
   {
    "duration": 82334,
    "start_time": "2022-05-31T03:24:29.555Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-31T03:25:56.583Z"
   },
   {
    "duration": 226,
    "start_time": "2022-05-31T03:25:59.151Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T03:26:40.421Z"
   },
   {
    "duration": 179638,
    "start_time": "2022-05-31T03:26:41.971Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-31T03:29:47.173Z"
   },
   {
    "duration": 1148,
    "start_time": "2022-05-31T03:29:50.643Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-31T03:33:35.747Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.332Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.335Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.336Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.337Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.338Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.339Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.340Z"
   },
   {
    "duration": 1,
    "start_time": "2022-05-31T03:47:24.340Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.342Z"
   },
   {
    "duration": 1,
    "start_time": "2022-05-31T03:47:24.342Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.343Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.344Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.345Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.346Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.348Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.348Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.349Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.350Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.400Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.400Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.402Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.403Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.404Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.405Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.406Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.407Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.408Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.409Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.411Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.411Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.412Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.413Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.414Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.416Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.416Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.417Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.418Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.419Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.420Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.421Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.422Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.423Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.423Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.424Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.425Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.426Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.427Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.428Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.429Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.430Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.431Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.432Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.433Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.434Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.435Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.499Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.501Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.502Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T03:47:24.503Z"
   },
   {
    "duration": 2124,
    "start_time": "2022-05-31T04:01:16.252Z"
   },
   {
    "duration": 215,
    "start_time": "2022-05-31T04:01:18.379Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T04:01:18.596Z"
   },
   {
    "duration": 1040,
    "start_time": "2022-05-31T04:01:18.601Z"
   },
   {
    "duration": 67,
    "start_time": "2022-05-31T04:01:19.642Z"
   },
   {
    "duration": 93,
    "start_time": "2022-05-31T04:01:19.711Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-31T04:01:19.806Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-31T04:01:19.817Z"
   },
   {
    "duration": 184,
    "start_time": "2022-05-31T04:01:19.830Z"
   },
   {
    "duration": 796,
    "start_time": "2022-05-31T04:01:20.016Z"
   },
   {
    "duration": 1588,
    "start_time": "2022-05-31T04:01:20.815Z"
   },
   {
    "duration": 302,
    "start_time": "2022-05-31T04:01:22.404Z"
   },
   {
    "duration": 265,
    "start_time": "2022-05-31T04:01:22.708Z"
   },
   {
    "duration": 280,
    "start_time": "2022-05-31T04:01:22.975Z"
   },
   {
    "duration": 3789,
    "start_time": "2022-05-31T04:01:23.257Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T04:01:27.049Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-31T04:01:27.054Z"
   },
   {
    "duration": 42832,
    "start_time": "2022-05-31T04:01:27.073Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:09.907Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:09.909Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:09.910Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:09.911Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:09.912Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:09.913Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:09.914Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:09.915Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:09.920Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:09.921Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:09.922Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:09.923Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:09.924Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:09.925Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:09.926Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:09.927Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:09.928Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:09.929Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:09.930Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:09.931Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:09.932Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:09.933Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:09.933Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:09.934Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:09.935Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:09.937Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:09.938Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:09.939Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:09.940Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:09.941Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:09.942Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:10.000Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:10.001Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:10.002Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:10.003Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:10.004Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:10.005Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:10.006Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:10.007Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:10.008Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-31T04:02:10.009Z"
   },
   {
    "duration": 2182,
    "start_time": "2022-05-31T04:02:21.716Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-31T04:02:23.900Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-31T04:02:23.908Z"
   },
   {
    "duration": 1424,
    "start_time": "2022-05-31T04:02:23.918Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-31T04:02:25.399Z"
   },
   {
    "duration": 31,
    "start_time": "2022-05-31T04:02:25.411Z"
   },
   {
    "duration": 59,
    "start_time": "2022-05-31T04:02:25.443Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-31T04:02:25.504Z"
   },
   {
    "duration": 141,
    "start_time": "2022-05-31T04:02:25.517Z"
   },
   {
    "duration": 315,
    "start_time": "2022-05-31T04:02:25.661Z"
   },
   {
    "duration": 1408,
    "start_time": "2022-05-31T04:02:25.977Z"
   },
   {
    "duration": 258,
    "start_time": "2022-05-31T04:02:27.387Z"
   },
   {
    "duration": 232,
    "start_time": "2022-05-31T04:02:27.647Z"
   },
   {
    "duration": 260,
    "start_time": "2022-05-31T04:02:27.882Z"
   },
   {
    "duration": 3731,
    "start_time": "2022-05-31T04:02:28.144Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T04:02:31.877Z"
   },
   {
    "duration": 21,
    "start_time": "2022-05-31T04:02:31.882Z"
   },
   {
    "duration": 41493,
    "start_time": "2022-05-31T04:02:31.904Z"
   },
   {
    "duration": 31,
    "start_time": "2022-05-31T04:03:13.399Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-31T04:03:13.431Z"
   },
   {
    "duration": 96,
    "start_time": "2022-05-31T04:03:13.441Z"
   },
   {
    "duration": 2,
    "start_time": "2022-05-31T04:03:13.539Z"
   },
   {
    "duration": 41,
    "start_time": "2022-05-31T04:03:13.542Z"
   },
   {
    "duration": 31,
    "start_time": "2022-05-31T04:03:13.584Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-31T04:03:13.617Z"
   },
   {
    "duration": 6181,
    "start_time": "2022-05-31T04:03:13.622Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-31T04:03:19.804Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T04:03:19.813Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-31T04:03:19.818Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-31T04:03:19.833Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-31T04:03:19.842Z"
   },
   {
    "duration": 227326,
    "start_time": "2022-05-31T04:03:19.851Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-31T04:07:07.179Z"
   },
   {
    "duration": 8606,
    "start_time": "2022-05-31T04:07:07.186Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T04:07:15.793Z"
   },
   {
    "duration": 55221,
    "start_time": "2022-05-31T04:07:15.797Z"
   },
   {
    "duration": 20365,
    "start_time": "2022-05-31T04:08:11.020Z"
   },
   {
    "duration": 15,
    "start_time": "2022-05-31T04:08:31.387Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-31T04:08:31.403Z"
   },
   {
    "duration": 23,
    "start_time": "2022-05-31T04:08:31.412Z"
   },
   {
    "duration": 27,
    "start_time": "2022-05-31T04:08:31.437Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-31T04:08:31.466Z"
   },
   {
    "duration": 6917,
    "start_time": "2022-05-31T04:08:31.499Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T04:08:38.417Z"
   },
   {
    "duration": 64602,
    "start_time": "2022-05-31T04:08:38.422Z"
   },
   {
    "duration": 25776,
    "start_time": "2022-05-31T04:09:43.026Z"
   },
   {
    "duration": 275376,
    "start_time": "2022-05-31T04:10:08.804Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-31T04:14:44.182Z"
   },
   {
    "duration": 10792,
    "start_time": "2022-05-31T04:14:44.202Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-31T04:14:54.996Z"
   },
   {
    "duration": 58,
    "start_time": "2022-05-31T04:14:55.003Z"
   },
   {
    "duration": 3822,
    "start_time": "2022-05-31T04:14:55.063Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-31T04:14:58.887Z"
   },
   {
    "duration": 13208,
    "start_time": "2022-05-31T04:14:58.899Z"
   },
   {
    "duration": 7447,
    "start_time": "2022-05-31T04:15:12.109Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-31T04:15:19.558Z"
   },
   {
    "duration": 184788,
    "start_time": "2022-05-31T04:15:19.564Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-31T04:18:24.354Z"
   },
   {
    "duration": 3470,
    "start_time": "2022-05-31T04:18:24.363Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-31T04:24:37.059Z"
   },
   {
    "duration": 127520,
    "start_time": "2022-05-31T04:24:40.586Z"
   },
   {
    "duration": 166736,
    "start_time": "2022-05-31T04:27:20.183Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-31T04:30:13.494Z"
   },
   {
    "duration": 4441,
    "start_time": "2022-05-31T04:30:17.713Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-31T04:30:50.388Z"
   },
   {
    "duration": 1181948,
    "start_time": "2022-05-31T04:30:52.775Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-31T04:51:11.633Z"
   },
   {
    "duration": 124250,
    "start_time": "2022-05-31T04:51:14.865Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-31T04:55:23.138Z"
   },
   {
    "duration": 954539,
    "start_time": "2022-05-31T04:55:25.537Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "612px",
    "left": "811px",
    "top": "201.125px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
